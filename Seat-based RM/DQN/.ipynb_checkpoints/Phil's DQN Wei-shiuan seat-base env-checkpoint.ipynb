{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d03147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4eea459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3085c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Dynamic Programming, FCFS Simulated result'''\n",
    "dp = 60940\n",
    "fcfs = 45276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca40141",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Establish an aircraft'''\n",
    "class aircraft:\n",
    "\n",
    "    # Initialize aircraft\n",
    "    def __init__(self):\n",
    "        self.seat_capacity = 100\n",
    "        self.seat_type = ['Y', 'M', 'K']\n",
    "        self.seat_price = {'f': 0, 'Y': 800, 'M': 500, 'K': 450}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f61b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Demand model from Balaiyan et al.'''\n",
    "class demandmodel:\n",
    "    \n",
    "    # Initialize demand model\n",
    "    def __init__(self):\n",
    "        \n",
    "        # inherent attributes from aircraft class\n",
    "        self.aircraft = aircraft()\n",
    "        self.seat_set = self.aircraft.seat_type\n",
    "        self.seat_price = self.aircraft.seat_price\n",
    "        \n",
    "        # demand model parameters\n",
    "        self.total_booking = 105\n",
    "        self.market_share = 0.25\n",
    "        self.gamma = 0.08426\n",
    "        self.alpha = 0.001251\n",
    "        self.beta = {'DFARE':-0.006, 'LOT3':-0.944}\n",
    "        self.a = {'Y':{'DFARE':800, 'LOT3':1},\n",
    "                  'M':{'DFARE':500, 'LOT3':1},\n",
    "                  'K':{'DFARE':450, 'LOT3':1},\n",
    "                 }\n",
    "        self.fare_diff_avg = sum(self.seat_price.values()) / len(self.seat_price)\n",
    "        for seat_type in self.a:\n",
    "            self.a[seat_type]['DFARE'] = round(self.a[seat_type]['DFARE'] - self.fare_diff_avg, 2)\n",
    "\n",
    "    # Calculate dm\n",
    "    def dm(self):\n",
    "        dm = self.total_booking/self.market_share\n",
    "        return dm\n",
    "\n",
    "    # Calcilate booking curve\n",
    "    def booking_curve(self, RD2, RD1):\n",
    "        booking_curve = math.exp(-self.gamma*RD2)-math.exp(-self.gamma*RD1)\n",
    "        return booking_curve\n",
    "\n",
    "    # find pj+1\n",
    "    def find_pj1(self, seat):\n",
    "        smaller_keys = [key for key in self.seat_price.keys() if key < seat]\n",
    "        if smaller_keys:\n",
    "            max_smaller_key = max(smaller_keys)\n",
    "            pj1 = self.seat_price[max_smaller_key]\n",
    "        else:\n",
    "            pj1 = min(self.seat_price.values())\n",
    "        return pj1\n",
    "\n",
    "    # Multinomial logit model\n",
    "    def mnl(self):\n",
    "        choose_prob = {}\n",
    "        value_dict = {}\n",
    "        for seat in self.seat_set:\n",
    "            result = {key: self.beta[key] * value for key, value in self.a[seat].items()}\n",
    "            total = sum(result.values())\n",
    "            value = math.exp(total)\n",
    "            value_dict[seat] = value\n",
    "        for seat in value_dict:\n",
    "            exp_value = math.exp(value_dict[seat])\n",
    "            choose_prob[seat] = exp_value / sum(math.exp(value) for value in value_dict.values())\n",
    "        # print(\"mnl: \", choose_prob)\n",
    "        return choose_prob\n",
    "\n",
    "    # Calculate customer choice\n",
    "    def customer_choice(self, seat_type):\n",
    "        total_sum = 0\n",
    "        choose_prob = self.mnl()\n",
    "        min_key = min(self.seat_price, key=self.seat_price.get)\n",
    "        p0 = self.seat_price[min_key]\n",
    "        for seat in self.seat_set:\n",
    "            pj = self.seat_price['Y'] # 暫時寫這樣\n",
    "            pj1 = self.seat_price['M'] # 暫時寫這樣\n",
    "            # print('p0: ',p0 , 'p1: ', pj, 'pj1: ', pj1)\n",
    "            sum_of_set = (math.exp(-self.alpha*(pj-p0))-math.exp(-self.alpha*(pj1-p0))) * choose_prob[seat_type] \n",
    "            # print('sum of set: ', sum_of_set)\n",
    "            total_sum += sum_of_set\n",
    "        return total_sum\n",
    "\n",
    "    # Calculate demand\n",
    "    def formulation(self, RD2, RD1):\n",
    "        dm = self.dm()\n",
    "        # print('dm',dm)\n",
    "        booking_curve = self.booking_curve(RD2, RD1)\n",
    "        # print('booking curve: ',booking_curve)\n",
    "        BR_dict = {}\n",
    "        \n",
    "        for seat in self.seat_set:\n",
    "            # print(\"calculate\", seat, \" ing...\")\n",
    "            customer_choice = self.customer_choice(seat)\n",
    "            # print('customer choice', customer_choice)\n",
    "            BR = dm * booking_curve * customer_choice\n",
    "            BR_dict[seat] = BR\n",
    "            # print(' seat: ', seat, ' predicted demand model from ', RD2,' to ', RD1, 'is', BR)\n",
    "        # print(\"total demand: \", sum(BR_dict.values()))\n",
    "        return BR_dict\n",
    "    \n",
    "    # Plot demand result\n",
    "    def plot_demand(self):\n",
    "        \n",
    "        # Store calculated result\n",
    "        every_rd = {seat: [] for seat in model.seat_set}  \n",
    "        cumulative_demand = {seat: [] for seat in model.seat_set}  \n",
    "        total_demand = {seat: 0 for seat in model.seat_set}  \n",
    "        cumulative_total_demand_per_rd = []  # Store each RD cumulative demand\n",
    "\n",
    "        # Calculate all RD demand\n",
    "        cumulative_total_demand = 0  # Initialize cumulative demand\n",
    "        for i in range(2, max_rd+1):\n",
    "            # print('i: ', i)\n",
    "            BR_results = model.formulation(i, i-1)  \n",
    "            total_demand_rd = sum(BR_results.values())  # Calculate demand form all rd\n",
    "            cumulative_total_demand += total_demand_rd  # update cumulative total deamnd\n",
    "            cumulative_total_demand_per_rd.append(cumulative_total_demand)  # append cumulative total demand\n",
    "            for seat, demand in BR_results.items():  \n",
    "                every_rd[seat].append(demand) \n",
    "                total_demand[seat] += demand  \n",
    "                cumulative_demand[seat].append(total_demand[seat])  \n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(range(1, max_rd), cumulative_total_demand_per_rd, label='Total Demand')\n",
    "        plt.xlabel('RD')\n",
    "        plt.ylabel('Total Demand')\n",
    "        plt.title('Total Demand Model')\n",
    "        plt.legend()\n",
    "        plt.xticks(range(0, max_rd, int(max_rd/10)))\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa426365",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Action space'''\n",
    "class AgentActionSpace:\n",
    "    def __init__(self):\n",
    "        # self.action_list = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "        self.action_list = [0, 1, 2, 3]\n",
    "        self.n = len(self.action_list)  \n",
    "\n",
    "    def sample(self):\n",
    "        return np.random.choice(self.action_list)\n",
    "\n",
    "    def contains(self, action):\n",
    "        return action in self.action_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784db100",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Uniform distribution'''\n",
    "class uniform_distribution:\n",
    "\n",
    "    # Initialize parameters\n",
    "    def __init__(self, total_demand, total_lambda):\n",
    "        self.total_demand = total_demand\n",
    "        self.total_lambda = total_lambda\n",
    "        self.num_period = int(total_demand/total_lambda)\n",
    "        self.prob = {'Bus1': 0.1, 'Bus2': 0.2, 'Leis1': 0.2, 'Leis2': 0.2, 'Leis3': 0.3}\n",
    "    \n",
    "    # Calculate lambda for each type of customer\n",
    "    def calculate_lambda(self):\n",
    "        lambda_list = []\n",
    "        lambda_list.append(round(1-self.total_lambda, 2))\n",
    "        for customer in self.prob:\n",
    "            lambda_list.append(round(self.prob[customer] * self.total_lambda, 2)) \n",
    "        # print(\"lambda_list: \", lambda_list)\n",
    "        return lambda_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032efff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Establish Customer class'''\n",
    "class Customer:\n",
    "\n",
    "    ''' Initialization '''\n",
    "    def __init__(self, total_demand, total_lambda):\n",
    "        self.customer_type = {0: 'f', 1: 'Bus1', 2:'Bus2', 3:'Leis1', 4: 'Leis2', 5: 'Leis3'}\n",
    "        self.num_customer_type = len(self.customer_type)\n",
    "        self.customer_preference = {\n",
    "            'f':{'Y': False, 'M': False, 'K': False},\n",
    "            'Bus1': {'Y': True, 'M': False, 'K': False},\n",
    "            'Bus2': {'Y': True, 'M': True, 'K': False},\n",
    "            'Leis1': {'Y': False, 'M': True, 'K': False},\n",
    "            'Leis2': {'Y': False, 'M': True, 'K': True},\n",
    "            'Leis3': {'Y': False, 'M': False, 'K': True},\n",
    "        }\n",
    "\n",
    "        # inherent from uniform distribution class\n",
    "        self.uniform_distribution = uniform_distribution(total_demand, total_lambda)\n",
    "        self.arrival_rates = self.uniform_distribution.calculate_lambda() # calculate arrival rates for each customer type\n",
    "        \n",
    "        # inherent from aircraft class\n",
    "        self.aircraft = aircraft()\n",
    "        self.seat_price = self.aircraft.seat_price\n",
    "\n",
    "    '''Customer generation'''\n",
    "    def generate_customer(self):\n",
    "        random_number = np.random.rand() # generate random number\n",
    "        probabilities = self.arrival_rates # arrival rates list\n",
    "        cumulative_probability = 0 # Use cumulative probability decide customer type\n",
    "        customer_index = 0\n",
    "        for probability in probabilities:\n",
    "            cumulative_probability += probability\n",
    "            if random_number <= cumulative_probability:\n",
    "                break\n",
    "            customer_index += 1\n",
    "        customer_type = self.customer_type[customer_index] # return customer will buy what kind of seat   \n",
    "        # print(f\"random_number: {random_number}, customer_index: {customer_index}, customer_type: {customer_type}\")\n",
    "        return customer_type\n",
    "\n",
    "    '''customer's preference seat under control'''\n",
    "    def preference_seat(self, customer_type, seat_open):\n",
    "        preferred_seats = []  \n",
    "        preferences = self.customer_preference[customer_type]  \n",
    "        for seat_type, preference in preferences.items():\n",
    "            if preference and seat_type in seat_open:\n",
    "                preferred_seats.append(seat_type)\n",
    "        # print(\"preference seats: \", preferred_seats)\n",
    "        return preferred_seats  \n",
    "    \n",
    "    '''customer make decision'''\n",
    "    def make_decision(self, customer_type, seat_open):\n",
    "        preferred_seats = self.preference_seat(customer_type, seat_open)  \n",
    "        if preferred_seats:\n",
    "            cheapest_seat = min(preferred_seats, key=lambda x: self.seat_price[x])\n",
    "            return cheapest_seat\n",
    "        else:\n",
    "            return 'f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ff1cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Establish env with Single Cabin mulitiple fare classes'''\n",
    "class AirlineEnvironment:\n",
    "    \n",
    "    '''Initialize env parameters'''\n",
    "    def __init__(self, name):\n",
    "        \n",
    "        # name of env\n",
    "        self.name = name\n",
    "        \n",
    "        # inherent aircraft\n",
    "        self.aircraft = aircraft()\n",
    "        self.seat_capacity = self.aircraft.seat_capacity # seat limitation\n",
    "        self.seat_type = self.aircraft.seat_type # seat type\n",
    "        \n",
    "        # inherent action space class\n",
    "        self.action_space = AgentActionSpace() \n",
    "        \n",
    "        # inherent attributes from demand model\n",
    "        self.max_rd = 20 # total selling RDs\n",
    "        self.demand_model = demandmodel()\n",
    "        self.total_demand = sum(self.demand_model.formulation(self.max_rd, 1).values()) # total demand from demand model\n",
    "        self.total_lambda = 0.8 # total lambda from test\n",
    "        self.max_period = int(self.total_demand/self.total_lambda) # total period\n",
    "        \n",
    "        # inherent attributes from uniform distribution class\n",
    "        self.uniform_distribution = uniform_distribution(self.total_demand, self.total_lambda)\n",
    "        self.arrival_rates = self.uniform_distribution.calculate_lambda() # calculate arrival rates for each customer type\n",
    "\n",
    "        # inherent attributes from Customer class\n",
    "        self.customer = Customer(self.total_demand, self.total_lambda) \n",
    "        \n",
    "        # environment parameters\n",
    "        self.seat_remain = self.seat_capacity # seat limitation\n",
    "        self.state = np.array([self.seat_capacity, self.max_period]) # Initialize state : (num seat sold, period)\n",
    "        # self.a_s_ref = {0: 'f', 1: 'Y', 2: 'M', 3: 'K', 4: 'YM', 5: 'YK', 6: 'MK', 7: 'YMK'} # action reference to seat open combination\n",
    "        self.a_s_ref = {0: 'f', 1: 'Y', 2: 'YK', 3: 'YMK'}\n",
    "    \n",
    "    '''reset env'''\n",
    "    def reset(self):\n",
    "        self.seat_remain = self.seat_capacity # Initialize total seat \n",
    "        self.state = np.array([self.seat_remain, self.max_period])  # Initialize state\n",
    "        return self.state\n",
    "    \n",
    "    '''Step'''\n",
    "    def step(self, state, action):\n",
    "\n",
    "        # print(f\"Action: {action}, state: {state}\")\n",
    "        \n",
    "        # With remaining seat\n",
    "        if self.seat_remain > 0:\n",
    "\n",
    "            # Agent choose a seat combination\n",
    "            seat_open = self.a_s_ref[action]   \n",
    "            # print(\"seat_open: \", seat_open)\n",
    "            \n",
    "            # Customer generation\n",
    "            customer_type = self.customer.generate_customer()\n",
    "            # print(\"customer type: \", customer_type)\n",
    "\n",
    "            # Customer choose seat\n",
    "            chosen_seat = self.customer.make_decision(customer_type, seat_open) \n",
    "            # print(\"chosen seat: \", chosen_seat)\n",
    "\n",
    "            # Decide immediate revenue\n",
    "            reward = self.aircraft.seat_price[chosen_seat] \n",
    "\n",
    "            # Update seat remain\n",
    "            if reward > 0:\n",
    "                self.seat_remain = self.seat_remain-1\n",
    "        \n",
    "        # Without remaining seat \n",
    "        else:\n",
    "            # print(\"No remaining seat.\")\n",
    "            reward = 0\n",
    "\n",
    "        # Update period\n",
    "        next_time = state[1].item() - 1\n",
    "        \n",
    "        # Check departure or not \n",
    "        departure = (next_time <= 0)\n",
    "\n",
    "        # update state\n",
    "        state[0] = self.seat_remain\n",
    "        state[1] = next_time\n",
    "        return state, reward, departure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e27f316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Deep Q Network'''\n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, n_actions, input_dims):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dims, 512)\n",
    "        self.fc2 = nn.Linear(512, n_actions)\n",
    "\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n",
    "\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        actions = self.fc2(x)\n",
    "\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38f8bb07-026a-4a25-8942-534bd2687bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define replay buffer'''\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, max_size, input_shape, n_actions):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_shape),\n",
    "                                     dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_shape),\n",
    "                                         dtype=np.float32)\n",
    "\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int64)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool_)\n",
    "\n",
    "    # store transition to buffer\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    # sample transition from buffer\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "\n",
    "        states = self.state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        states_ = self.new_state_memory[batch]\n",
    "        terminal = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, states_, terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57988436-6fdd-4f89-a63b-e997d94f28e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Define DQN agent'''\n",
    "class DQNAgent(object):\n",
    "    def __init__(self, gamma, epsilon, lr, n_actions, input_dims,\n",
    "                 mem_size, batch_size, eps_min, eps_dec, replace):\n",
    "        self.gamma = gamma # time discount gamma\n",
    "        self.epsilon = epsilon # epilson-greedy hyperparameter eplison\n",
    "        self.lr = lr # learning rate\n",
    "        self.n_actions = n_actions # number of action\n",
    "        self.input_dims = input_dims # number of state\n",
    "        self.batch_size = batch_size # batch size of sample memory\n",
    "        self.eps_min = eps_min # minimum of hyperparameter epilson\n",
    "        self.eps_dec = eps_dec # epilson decay rate, higher represent slower decay\n",
    "        self.replace_target_cnt = replace # frequence of replace target network \n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.learn_step_counter = 0\n",
    "        self.memory = ReplayBuffer(mem_size, (input_dims,), n_actions) # Replay buffer\n",
    "        self.q_eval = DeepQNetwork(self.lr, self.n_actions,\n",
    "                                    input_dims=self.input_dims) # Target network\n",
    "        self.q_next = DeepQNetwork(self.lr, self.n_actions,\n",
    "                                    input_dims=self.input_dims) # Policy network\n",
    "\n",
    "    # agent choose action\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon: # exploit: selection max value column\n",
    "            state = T.tensor([observation],dtype=T.float).to(self.q_eval.device)\n",
    "            actions = self.q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else: # explore: randomly select aciton\n",
    "            action = np.random.choice(self.action_space)\n",
    "        return action\n",
    "\n",
    "    # store transition\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        self.memory.store_transition(state, action, reward, state_, done)\n",
    "\n",
    "    # sample memory\n",
    "    def sample_memory(self):\n",
    "        state, action, reward, new_state, done = \\\n",
    "                                self.memory.sample_buffer(self.batch_size)\n",
    "        states = T.tensor(state).to(self.q_eval.device)\n",
    "        rewards = T.tensor(reward).to(self.q_eval.device)\n",
    "        dones = T.tensor(done).to(self.q_eval.device)\n",
    "        actions = T.tensor(action).to(self.q_eval.device)\n",
    "        states_ = T.tensor(new_state).to(self.q_eval.device)\n",
    "        return states, actions, rewards, states_, dones\n",
    "\n",
    "    # update parameter of target network\n",
    "    def replace_target_network(self):\n",
    "        if self.learn_step_counter % self.replace_target_cnt == 0:\n",
    "            self.q_next.load_state_dict(self.q_eval.state_dict())\n",
    "\n",
    "    # decrease value of epilson\n",
    "    def decrement_epsilon(self):\n",
    "        self.epsilon = self.epsilon - self.eps_dec \\\n",
    "                           if self.epsilon > self.eps_min else self.eps_min\n",
    "\n",
    "    # optimizer model\n",
    "    def learn(self):\n",
    "\n",
    "        if self.memory.mem_cntr < self.batch_size: # check whether have enough memory\n",
    "            return\n",
    "\n",
    "        self.q_eval.optimizer.zero_grad() # diminish previous gradient\n",
    "\n",
    "        self.replace_target_network()\n",
    "\n",
    "        states, actions, rewards, states_, dones = self.sample_memory()\n",
    "        indices = np.arange(self.batch_size)\n",
    "\n",
    "        q_pred = self.q_eval.forward(states)[indices, actions]\n",
    "        q_next = self.q_next.forward(states_).max(dim=1)[0]\n",
    "\n",
    "        q_next[dones] = 0.0\n",
    "        q_target = rewards + self.gamma*q_next\n",
    "\n",
    "        loss = self.q_eval.loss(q_target, q_pred).to(self.q_eval.device)\n",
    "        loss.backward()\n",
    "        self.q_eval.optimizer.step()\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        self.decrement_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526bd8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total Revenue: 53850  Cumulative average 53850.0 best score: 53850 epsilon 1.00 steps 193\n",
      "Episode: 2 Total Revenue: 45700  Cumulative average 49775.0 best score: 53850 epsilon 1.00 steps 386\n",
      "Episode: 3 Total Revenue: 46950  Cumulative average 48833.3 best score: 53850 epsilon 1.00 steps 579\n",
      "Episode: 4 Total Revenue: 51500  Cumulative average 49500.0 best score: 53850 epsilon 1.00 steps 772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_47492\\99049053.py:25: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  state = T.tensor([observation],dtype=T.float).to(self.q_eval.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5 Total Revenue: 48900  Cumulative average 49380.0 best score: 53850 epsilon 1.00 steps 965\n",
      "Episode: 6 Total Revenue: 41450  Cumulative average 48058.3 best score: 53850 epsilon 0.99 steps 1158\n",
      "Episode: 7 Total Revenue: 50500  Cumulative average 48407.1 best score: 53850 epsilon 0.99 steps 1351\n",
      "Episode: 8 Total Revenue: 41900  Cumulative average 47593.8 best score: 53850 epsilon 0.99 steps 1544\n",
      "Episode: 9 Total Revenue: 50000  Cumulative average 47861.1 best score: 53850 epsilon 0.99 steps 1737\n",
      "Episode: 10 Total Revenue: 48700  Cumulative average 47945.0 best score: 53850 epsilon 0.99 steps 1930\n",
      "Episode: 11 Total Revenue: 48950  Cumulative average 48036.4 best score: 53850 epsilon 0.98 steps 2123\n",
      "Episode: 12 Total Revenue: 41150  Cumulative average 47462.5 best score: 53850 epsilon 0.98 steps 2316\n",
      "Episode: 13 Total Revenue: 46100  Cumulative average 47357.7 best score: 53850 epsilon 0.98 steps 2509\n",
      "Episode: 14 Total Revenue: 55600  Cumulative average 47946.4 best score: 55600 epsilon 0.98 steps 2702\n",
      "Episode: 15 Total Revenue: 40450  Cumulative average 47446.7 best score: 55600 epsilon 0.98 steps 2895\n",
      "Episode: 16 Total Revenue: 47700  Cumulative average 47462.5 best score: 55600 epsilon 0.97 steps 3088\n",
      "Episode: 17 Total Revenue: 47350  Cumulative average 47455.9 best score: 55600 epsilon 0.97 steps 3281\n",
      "Episode: 18 Total Revenue: 45800  Cumulative average 47363.9 best score: 55600 epsilon 0.97 steps 3474\n",
      "Episode: 19 Total Revenue: 47950  Cumulative average 47394.7 best score: 55600 epsilon 0.97 steps 3667\n",
      "Episode: 20 Total Revenue: 51900  Cumulative average 47620.0 best score: 55600 epsilon 0.97 steps 3860\n",
      "Episode: 21 Total Revenue: 52150  Cumulative average 47835.7 best score: 55600 epsilon 0.96 steps 4053\n",
      "Episode: 22 Total Revenue: 50250  Cumulative average 47945.5 best score: 55600 epsilon 0.96 steps 4246\n",
      "Episode: 23 Total Revenue: 48750  Cumulative average 47980.4 best score: 55600 epsilon 0.96 steps 4439\n",
      "Episode: 24 Total Revenue: 46650  Cumulative average 47925.0 best score: 55600 epsilon 0.96 steps 4632\n",
      "Episode: 25 Total Revenue: 47550  Cumulative average 47910.0 best score: 55600 epsilon 0.96 steps 4825\n",
      "Episode: 26 Total Revenue: 49750  Cumulative average 47980.8 best score: 55600 epsilon 0.95 steps 5018\n",
      "Episode: 27 Total Revenue: 48750  Cumulative average 48009.3 best score: 55600 epsilon 0.95 steps 5211\n",
      "Episode: 28 Total Revenue: 41950  Cumulative average 47792.9 best score: 55600 epsilon 0.95 steps 5404\n",
      "Episode: 29 Total Revenue: 53800  Cumulative average 48000.0 best score: 55600 epsilon 0.95 steps 5597\n",
      "Episode: 30 Total Revenue: 42250  Cumulative average 47808.3 best score: 55600 epsilon 0.95 steps 5790\n",
      "Episode: 31 Total Revenue: 50500  Cumulative average 47895.2 best score: 55600 epsilon 0.95 steps 5983\n",
      "Episode: 32 Total Revenue: 46550  Cumulative average 47853.1 best score: 55600 epsilon 0.94 steps 6176\n",
      "Episode: 33 Total Revenue: 51350  Cumulative average 47959.1 best score: 55600 epsilon 0.94 steps 6369\n",
      "Episode: 34 Total Revenue: 44200  Cumulative average 47848.5 best score: 55600 epsilon 0.94 steps 6562\n",
      "Episode: 35 Total Revenue: 45350  Cumulative average 47777.1 best score: 55600 epsilon 0.94 steps 6755\n",
      "Episode: 36 Total Revenue: 43000  Cumulative average 47644.4 best score: 55600 epsilon 0.94 steps 6948\n",
      "Episode: 37 Total Revenue: 55200  Cumulative average 47848.6 best score: 55600 epsilon 0.93 steps 7141\n",
      "Episode: 38 Total Revenue: 50050  Cumulative average 47906.6 best score: 55600 epsilon 0.93 steps 7334\n",
      "Episode: 39 Total Revenue: 46350  Cumulative average 47866.7 best score: 55600 epsilon 0.93 steps 7527\n",
      "Episode: 40 Total Revenue: 57100  Cumulative average 48097.5 best score: 57100 epsilon 0.93 steps 7720\n",
      "Episode: 41 Total Revenue: 51700  Cumulative average 48185.4 best score: 57100 epsilon 0.93 steps 7913\n",
      "Episode: 42 Total Revenue: 50800  Cumulative average 48247.6 best score: 57100 epsilon 0.92 steps 8106\n",
      "Episode: 43 Total Revenue: 48500  Cumulative average 48253.5 best score: 57100 epsilon 0.92 steps 8299\n",
      "Episode: 44 Total Revenue: 44300  Cumulative average 48163.6 best score: 57100 epsilon 0.92 steps 8492\n",
      "Episode: 45 Total Revenue: 48050  Cumulative average 48161.1 best score: 57100 epsilon 0.92 steps 8685\n",
      "Episode: 46 Total Revenue: 47950  Cumulative average 48156.5 best score: 57100 epsilon 0.92 steps 8878\n",
      "Episode: 47 Total Revenue: 47350  Cumulative average 48139.4 best score: 57100 epsilon 0.91 steps 9071\n",
      "Episode: 48 Total Revenue: 40050  Cumulative average 47970.8 best score: 57100 epsilon 0.91 steps 9264\n",
      "Episode: 49 Total Revenue: 44450  Cumulative average 47899.0 best score: 57100 epsilon 0.91 steps 9457\n",
      "Episode: 50 Total Revenue: 47150  Cumulative average 47884.0 best score: 57100 epsilon 0.91 steps 9650\n",
      "Episode: 51 Total Revenue: 50200  Cumulative average 47929.4 best score: 57100 epsilon 0.91 steps 9843\n",
      "Episode: 52 Total Revenue: 46250  Cumulative average 47897.1 best score: 57100 epsilon 0.90 steps 10036\n",
      "Episode: 53 Total Revenue: 50900  Cumulative average 47953.8 best score: 57100 epsilon 0.90 steps 10229\n",
      "Episode: 54 Total Revenue: 50050  Cumulative average 47992.6 best score: 57100 epsilon 0.90 steps 10422\n",
      "Episode: 55 Total Revenue: 40600  Cumulative average 47858.2 best score: 57100 epsilon 0.90 steps 10615\n",
      "Episode: 56 Total Revenue: 54150  Cumulative average 47970.5 best score: 57100 epsilon 0.90 steps 10808\n",
      "Episode: 57 Total Revenue: 43550  Cumulative average 47893.0 best score: 57100 epsilon 0.90 steps 11001\n",
      "Episode: 58 Total Revenue: 54700  Cumulative average 48010.3 best score: 57100 epsilon 0.89 steps 11194\n",
      "Episode: 59 Total Revenue: 44100  Cumulative average 47944.1 best score: 57100 epsilon 0.89 steps 11387\n",
      "Episode: 60 Total Revenue: 47250  Cumulative average 47932.5 best score: 57100 epsilon 0.89 steps 11580\n",
      "Episode: 61 Total Revenue: 46600  Cumulative average 47910.7 best score: 57100 epsilon 0.89 steps 11773\n",
      "Episode: 62 Total Revenue: 48750  Cumulative average 47924.2 best score: 57100 epsilon 0.89 steps 11966\n",
      "Episode: 63 Total Revenue: 49550  Cumulative average 47950.0 best score: 57100 epsilon 0.88 steps 12159\n",
      "Episode: 64 Total Revenue: 54450  Cumulative average 48051.6 best score: 57100 epsilon 0.88 steps 12352\n",
      "Episode: 65 Total Revenue: 52650  Cumulative average 48122.3 best score: 57100 epsilon 0.88 steps 12545\n",
      "Episode: 66 Total Revenue: 51850  Cumulative average 48178.8 best score: 57100 epsilon 0.88 steps 12738\n",
      "Episode: 67 Total Revenue: 53400  Cumulative average 48256.7 best score: 57100 epsilon 0.88 steps 12931\n",
      "Episode: 68 Total Revenue: 50850  Cumulative average 48294.9 best score: 57100 epsilon 0.87 steps 13124\n",
      "Episode: 69 Total Revenue: 48350  Cumulative average 48295.7 best score: 57100 epsilon 0.87 steps 13317\n",
      "Episode: 70 Total Revenue: 54450  Cumulative average 48383.6 best score: 57100 epsilon 0.87 steps 13510\n",
      "Episode: 71 Total Revenue: 51650  Cumulative average 48429.6 best score: 57100 epsilon 0.87 steps 13703\n",
      "Episode: 72 Total Revenue: 45950  Cumulative average 48395.1 best score: 57100 epsilon 0.87 steps 13896\n",
      "Episode: 73 Total Revenue: 46950  Cumulative average 48375.3 best score: 57100 epsilon 0.86 steps 14089\n",
      "Episode: 74 Total Revenue: 51150  Cumulative average 48412.8 best score: 57100 epsilon 0.86 steps 14282\n",
      "Episode: 75 Total Revenue: 57000  Cumulative average 48527.3 best score: 57100 epsilon 0.86 steps 14475\n",
      "Episode: 76 Total Revenue: 52200  Cumulative average 48575.7 best score: 57100 epsilon 0.86 steps 14668\n",
      "Episode: 77 Total Revenue: 38600  Cumulative average 48446.1 best score: 57100 epsilon 0.86 steps 14861\n",
      "Episode: 78 Total Revenue: 50700  Cumulative average 48475.0 best score: 57100 epsilon 0.85 steps 15054\n",
      "Episode: 79 Total Revenue: 46100  Cumulative average 48444.9 best score: 57100 epsilon 0.85 steps 15247\n",
      "Episode: 80 Total Revenue: 57450  Cumulative average 48557.5 best score: 57450 epsilon 0.85 steps 15440\n",
      "Episode: 81 Total Revenue: 53150  Cumulative average 48614.2 best score: 57450 epsilon 0.85 steps 15633\n",
      "Episode: 82 Total Revenue: 46850  Cumulative average 48592.7 best score: 57450 epsilon 0.85 steps 15826\n",
      "Episode: 83 Total Revenue: 53150  Cumulative average 48647.6 best score: 57450 epsilon 0.84 steps 16019\n",
      "Episode: 84 Total Revenue: 48900  Cumulative average 48650.6 best score: 57450 epsilon 0.84 steps 16212\n",
      "Episode: 85 Total Revenue: 50000  Cumulative average 48666.5 best score: 57450 epsilon 0.84 steps 16405\n",
      "Episode: 86 Total Revenue: 51500  Cumulative average 48699.4 best score: 57450 epsilon 0.84 steps 16598\n",
      "Episode: 87 Total Revenue: 51750  Cumulative average 48734.5 best score: 57450 epsilon 0.84 steps 16791\n",
      "Episode: 88 Total Revenue: 54250  Cumulative average 48797.2 best score: 57450 epsilon 0.84 steps 16984\n",
      "Episode: 89 Total Revenue: 53400  Cumulative average 48848.9 best score: 57450 epsilon 0.83 steps 17177\n",
      "Episode: 90 Total Revenue: 44700  Cumulative average 48802.8 best score: 57450 epsilon 0.83 steps 17370\n",
      "Episode: 91 Total Revenue: 50700  Cumulative average 48823.6 best score: 57450 epsilon 0.83 steps 17563\n",
      "Episode: 92 Total Revenue: 47850  Cumulative average 48813.0 best score: 57450 epsilon 0.83 steps 17756\n",
      "Episode: 93 Total Revenue: 50250  Cumulative average 48828.5 best score: 57450 epsilon 0.83 steps 17949\n",
      "Episode: 94 Total Revenue: 50900  Cumulative average 48850.5 best score: 57450 epsilon 0.82 steps 18142\n",
      "Episode: 95 Total Revenue: 49700  Cumulative average 48859.5 best score: 57450 epsilon 0.82 steps 18335\n",
      "Episode: 96 Total Revenue: 55300  Cumulative average 48926.6 best score: 57450 epsilon 0.82 steps 18528\n",
      "Episode: 97 Total Revenue: 45650  Cumulative average 48892.8 best score: 57450 epsilon 0.82 steps 18721\n",
      "Episode: 98 Total Revenue: 55050  Cumulative average 48955.6 best score: 57450 epsilon 0.82 steps 18914\n",
      "Episode: 99 Total Revenue: 49200  Cumulative average 48958.1 best score: 57450 epsilon 0.81 steps 19107\n",
      "Episode: 100 Total Revenue: 56650  Cumulative average 49035.0 best score: 57450 epsilon 0.81 steps 19300\n",
      "Episode: 101 Total Revenue: 51350  Cumulative average 49057.9 best score: 57450 epsilon 0.81 steps 19493\n",
      "Episode: 102 Total Revenue: 48700  Cumulative average 49054.4 best score: 57450 epsilon 0.81 steps 19686\n",
      "Episode: 103 Total Revenue: 54950  Cumulative average 49111.7 best score: 57450 epsilon 0.81 steps 19879\n",
      "Episode: 104 Total Revenue: 55150  Cumulative average 49169.7 best score: 57450 epsilon 0.80 steps 20072\n",
      "Episode: 105 Total Revenue: 50250  Cumulative average 49180.0 best score: 57450 epsilon 0.80 steps 20265\n",
      "Episode: 106 Total Revenue: 52050  Cumulative average 49207.1 best score: 57450 epsilon 0.80 steps 20458\n",
      "Episode: 107 Total Revenue: 52400  Cumulative average 49236.9 best score: 57450 epsilon 0.80 steps 20651\n",
      "Episode: 108 Total Revenue: 48350  Cumulative average 49228.7 best score: 57450 epsilon 0.80 steps 20844\n",
      "Episode: 109 Total Revenue: 50050  Cumulative average 49236.2 best score: 57450 epsilon 0.79 steps 21037\n",
      "Episode: 110 Total Revenue: 48700  Cumulative average 49231.4 best score: 57450 epsilon 0.79 steps 21230\n",
      "Episode: 111 Total Revenue: 54900  Cumulative average 49282.4 best score: 57450 epsilon 0.79 steps 21423\n",
      "Episode: 112 Total Revenue: 51950  Cumulative average 49306.2 best score: 57450 epsilon 0.79 steps 21616\n",
      "Episode: 113 Total Revenue: 50100  Cumulative average 49313.3 best score: 57450 epsilon 0.79 steps 21809\n",
      "Episode: 114 Total Revenue: 52850  Cumulative average 49344.3 best score: 57450 epsilon 0.79 steps 22002\n",
      "Episode: 115 Total Revenue: 54850  Cumulative average 49392.2 best score: 57450 epsilon 0.78 steps 22195\n",
      "Episode: 116 Total Revenue: 44100  Cumulative average 49346.6 best score: 57450 epsilon 0.78 steps 22388\n",
      "Episode: 117 Total Revenue: 44950  Cumulative average 49309.0 best score: 57450 epsilon 0.78 steps 22581\n",
      "Episode: 118 Total Revenue: 48650  Cumulative average 49303.4 best score: 57450 epsilon 0.78 steps 22774\n",
      "Episode: 119 Total Revenue: 45550  Cumulative average 49271.8 best score: 57450 epsilon 0.78 steps 22967\n",
      "Episode: 120 Total Revenue: 53600  Cumulative average 49307.9 best score: 57450 epsilon 0.77 steps 23160\n",
      "Episode: 121 Total Revenue: 50150  Cumulative average 49314.9 best score: 57450 epsilon 0.77 steps 23353\n",
      "Episode: 122 Total Revenue: 53550  Cumulative average 49349.6 best score: 57450 epsilon 0.77 steps 23546\n",
      "Episode: 123 Total Revenue: 54850  Cumulative average 49394.3 best score: 57450 epsilon 0.77 steps 23739\n",
      "Episode: 124 Total Revenue: 54750  Cumulative average 49437.5 best score: 57450 epsilon 0.77 steps 23932\n",
      "Episode: 125 Total Revenue: 56450  Cumulative average 49493.6 best score: 57450 epsilon 0.76 steps 24125\n",
      "Episode: 126 Total Revenue: 53950  Cumulative average 49529.0 best score: 57450 epsilon 0.76 steps 24318\n",
      "Episode: 127 Total Revenue: 52400  Cumulative average 49551.6 best score: 57450 epsilon 0.76 steps 24511\n",
      "Episode: 128 Total Revenue: 52500  Cumulative average 49574.6 best score: 57450 epsilon 0.76 steps 24704\n",
      "Episode: 129 Total Revenue: 53150  Cumulative average 49602.3 best score: 57450 epsilon 0.76 steps 24897\n",
      "Episode: 130 Total Revenue: 52000  Cumulative average 49620.8 best score: 57450 epsilon 0.75 steps 25090\n",
      "Episode: 131 Total Revenue: 57450  Cumulative average 49680.5 best score: 57450 epsilon 0.75 steps 25283\n",
      "Episode: 132 Total Revenue: 50900  Cumulative average 49689.8 best score: 57450 epsilon 0.75 steps 25476\n",
      "Episode: 133 Total Revenue: 56950  Cumulative average 49744.4 best score: 57450 epsilon 0.75 steps 25669\n",
      "Episode: 134 Total Revenue: 53950  Cumulative average 49775.7 best score: 57450 epsilon 0.75 steps 25862\n",
      "Episode: 135 Total Revenue: 48350  Cumulative average 49765.2 best score: 57450 epsilon 0.74 steps 26055\n",
      "Episode: 136 Total Revenue: 55650  Cumulative average 49808.5 best score: 57450 epsilon 0.74 steps 26248\n",
      "Episode: 137 Total Revenue: 55350  Cumulative average 49848.9 best score: 57450 epsilon 0.74 steps 26441\n",
      "Episode: 138 Total Revenue: 55750  Cumulative average 49891.7 best score: 57450 epsilon 0.74 steps 26634\n",
      "Episode: 139 Total Revenue: 51400  Cumulative average 49902.5 best score: 57450 epsilon 0.74 steps 26827\n",
      "Episode: 140 Total Revenue: 52800  Cumulative average 49923.2 best score: 57450 epsilon 0.73 steps 27020\n",
      "Episode: 141 Total Revenue: 54400  Cumulative average 49955.0 best score: 57450 epsilon 0.73 steps 27213\n",
      "Episode: 142 Total Revenue: 55050  Cumulative average 49990.8 best score: 57450 epsilon 0.73 steps 27406\n",
      "Episode: 143 Total Revenue: 54600  Cumulative average 50023.1 best score: 57450 epsilon 0.73 steps 27599\n",
      "Episode: 144 Total Revenue: 56450  Cumulative average 50067.7 best score: 57450 epsilon 0.73 steps 27792\n",
      "Episode: 145 Total Revenue: 54550  Cumulative average 50098.6 best score: 57450 epsilon 0.73 steps 27985\n",
      "Episode: 146 Total Revenue: 52350  Cumulative average 50114.0 best score: 57450 epsilon 0.72 steps 28178\n",
      "Episode: 147 Total Revenue: 53100  Cumulative average 50134.4 best score: 57450 epsilon 0.72 steps 28371\n",
      "Episode: 148 Total Revenue: 55000  Cumulative average 50167.2 best score: 57450 epsilon 0.72 steps 28564\n",
      "Episode: 149 Total Revenue: 48700  Cumulative average 50157.4 best score: 57450 epsilon 0.72 steps 28757\n",
      "Episode: 150 Total Revenue: 49950  Cumulative average 50156.0 best score: 57450 epsilon 0.72 steps 28950\n",
      "Episode: 151 Total Revenue: 51400  Cumulative average 50164.2 best score: 57450 epsilon 0.71 steps 29143\n",
      "Episode: 152 Total Revenue: 52800  Cumulative average 50181.6 best score: 57450 epsilon 0.71 steps 29336\n",
      "Episode: 153 Total Revenue: 52400  Cumulative average 50196.1 best score: 57450 epsilon 0.71 steps 29529\n",
      "Episode: 154 Total Revenue: 56000  Cumulative average 50233.8 best score: 57450 epsilon 0.71 steps 29722\n",
      "Episode: 155 Total Revenue: 54600  Cumulative average 50261.9 best score: 57450 epsilon 0.71 steps 29915\n",
      "Episode: 156 Total Revenue: 55900  Cumulative average 50298.1 best score: 57450 epsilon 0.70 steps 30108\n",
      "Episode: 157 Total Revenue: 54550  Cumulative average 50325.2 best score: 57450 epsilon 0.70 steps 30301\n",
      "Episode: 158 Total Revenue: 55450  Cumulative average 50357.6 best score: 57450 epsilon 0.70 steps 30494\n",
      "Episode: 159 Total Revenue: 53150  Cumulative average 50375.2 best score: 57450 epsilon 0.70 steps 30687\n",
      "Episode: 160 Total Revenue: 51650  Cumulative average 50383.1 best score: 57450 epsilon 0.70 steps 30880\n",
      "Episode: 161 Total Revenue: 51150  Cumulative average 50387.9 best score: 57450 epsilon 0.69 steps 31073\n",
      "Episode: 162 Total Revenue: 54600  Cumulative average 50413.9 best score: 57450 epsilon 0.69 steps 31266\n",
      "Episode: 163 Total Revenue: 57400  Cumulative average 50456.7 best score: 57450 epsilon 0.69 steps 31459\n",
      "Episode: 164 Total Revenue: 53050  Cumulative average 50472.6 best score: 57450 epsilon 0.69 steps 31652\n",
      "Episode: 165 Total Revenue: 52150  Cumulative average 50482.7 best score: 57450 epsilon 0.69 steps 31845\n",
      "Episode: 166 Total Revenue: 49150  Cumulative average 50474.7 best score: 57450 epsilon 0.68 steps 32038\n",
      "Episode: 167 Total Revenue: 52950  Cumulative average 50489.5 best score: 57450 epsilon 0.68 steps 32231\n",
      "Episode: 168 Total Revenue: 48550  Cumulative average 50478.0 best score: 57450 epsilon 0.68 steps 32424\n",
      "Episode: 169 Total Revenue: 54300  Cumulative average 50500.6 best score: 57450 epsilon 0.68 steps 32617\n",
      "Episode: 170 Total Revenue: 54650  Cumulative average 50525.0 best score: 57450 epsilon 0.68 steps 32810\n",
      "Episode: 171 Total Revenue: 53700  Cumulative average 50543.6 best score: 57450 epsilon 0.68 steps 33003\n",
      "Episode: 172 Total Revenue: 55300  Cumulative average 50571.2 best score: 57450 epsilon 0.67 steps 33196\n",
      "Episode: 173 Total Revenue: 55400  Cumulative average 50599.1 best score: 57450 epsilon 0.67 steps 33389\n",
      "Episode: 174 Total Revenue: 53250  Cumulative average 50614.4 best score: 57450 epsilon 0.67 steps 33582\n",
      "Episode: 175 Total Revenue: 52750  Cumulative average 50626.6 best score: 57450 epsilon 0.67 steps 33775\n",
      "Episode: 176 Total Revenue: 56600  Cumulative average 50660.5 best score: 57450 epsilon 0.67 steps 33968\n",
      "Episode: 177 Total Revenue: 54550  Cumulative average 50682.5 best score: 57450 epsilon 0.66 steps 34161\n",
      "Episode: 178 Total Revenue: 53550  Cumulative average 50698.6 best score: 57450 epsilon 0.66 steps 34354\n",
      "Episode: 179 Total Revenue: 56700  Cumulative average 50732.1 best score: 57450 epsilon 0.66 steps 34547\n",
      "Episode: 180 Total Revenue: 55850  Cumulative average 50760.6 best score: 57450 epsilon 0.66 steps 34740\n",
      "Episode: 181 Total Revenue: 54000  Cumulative average 50778.5 best score: 57450 epsilon 0.66 steps 34933\n",
      "Episode: 182 Total Revenue: 54700  Cumulative average 50800.0 best score: 57450 epsilon 0.65 steps 35126\n",
      "Episode: 183 Total Revenue: 54100  Cumulative average 50818.0 best score: 57450 epsilon 0.65 steps 35319\n",
      "Episode: 184 Total Revenue: 57500  Cumulative average 50854.3 best score: 57500 epsilon 0.65 steps 35512\n",
      "Episode: 185 Total Revenue: 57200  Cumulative average 50888.6 best score: 57500 epsilon 0.65 steps 35705\n",
      "Episode: 186 Total Revenue: 53750  Cumulative average 50904.0 best score: 57500 epsilon 0.65 steps 35898\n",
      "Episode: 187 Total Revenue: 50100  Cumulative average 50899.7 best score: 57500 epsilon 0.64 steps 36091\n",
      "Episode: 188 Total Revenue: 54200  Cumulative average 50917.3 best score: 57500 epsilon 0.64 steps 36284\n",
      "Episode: 189 Total Revenue: 55650  Cumulative average 50942.3 best score: 57500 epsilon 0.64 steps 36477\n",
      "Episode: 190 Total Revenue: 55650  Cumulative average 50967.1 best score: 57500 epsilon 0.64 steps 36670\n",
      "Episode: 191 Total Revenue: 54300  Cumulative average 50984.6 best score: 57500 epsilon 0.64 steps 36863\n",
      "Episode: 192 Total Revenue: 55050  Cumulative average 51005.7 best score: 57500 epsilon 0.63 steps 37056\n",
      "Episode: 193 Total Revenue: 54600  Cumulative average 51024.4 best score: 57500 epsilon 0.63 steps 37249\n",
      "Episode: 194 Total Revenue: 51000  Cumulative average 51024.2 best score: 57500 epsilon 0.63 steps 37442\n",
      "Episode: 195 Total Revenue: 55400  Cumulative average 51046.7 best score: 57500 epsilon 0.63 steps 37635\n",
      "Episode: 196 Total Revenue: 52100  Cumulative average 51052.0 best score: 57500 epsilon 0.63 steps 37828\n",
      "Episode: 197 Total Revenue: 54100  Cumulative average 51067.5 best score: 57500 epsilon 0.62 steps 38021\n",
      "Episode: 198 Total Revenue: 56700  Cumulative average 51096.0 best score: 57500 epsilon 0.62 steps 38214\n",
      "Episode: 199 Total Revenue: 53750  Cumulative average 51109.3 best score: 57500 epsilon 0.62 steps 38407\n",
      "Episode: 200 Total Revenue: 54850  Cumulative average 51128.0 best score: 57500 epsilon 0.62 steps 38600\n",
      "Episode: 201 Total Revenue: 54250  Cumulative average 51143.5 best score: 57500 epsilon 0.62 steps 38793\n",
      "Episode: 202 Total Revenue: 53250  Cumulative average 51154.0 best score: 57500 epsilon 0.62 steps 38986\n",
      "Episode: 203 Total Revenue: 50050  Cumulative average 51148.5 best score: 57500 epsilon 0.61 steps 39179\n",
      "Episode: 204 Total Revenue: 55900  Cumulative average 51171.8 best score: 57500 epsilon 0.61 steps 39372\n",
      "Episode: 205 Total Revenue: 54200  Cumulative average 51186.6 best score: 57500 epsilon 0.61 steps 39565\n",
      "Episode: 206 Total Revenue: 56100  Cumulative average 51210.4 best score: 57500 epsilon 0.61 steps 39758\n",
      "Episode: 207 Total Revenue: 55300  Cumulative average 51230.2 best score: 57500 epsilon 0.61 steps 39951\n",
      "Episode: 208 Total Revenue: 53050  Cumulative average 51238.9 best score: 57500 epsilon 0.60 steps 40144\n",
      "Episode: 209 Total Revenue: 55400  Cumulative average 51258.9 best score: 57500 epsilon 0.60 steps 40337\n",
      "Episode: 210 Total Revenue: 52600  Cumulative average 51265.2 best score: 57500 epsilon 0.60 steps 40530\n",
      "Episode: 211 Total Revenue: 52950  Cumulative average 51273.2 best score: 57500 epsilon 0.60 steps 40723\n",
      "Episode: 212 Total Revenue: 53200  Cumulative average 51282.3 best score: 57500 epsilon 0.60 steps 40916\n",
      "Episode: 213 Total Revenue: 53050  Cumulative average 51290.6 best score: 57500 epsilon 0.59 steps 41109\n",
      "Episode: 214 Total Revenue: 52450  Cumulative average 51296.0 best score: 57500 epsilon 0.59 steps 41302\n",
      "Episode: 215 Total Revenue: 53700  Cumulative average 51307.2 best score: 57500 epsilon 0.59 steps 41495\n",
      "Episode: 216 Total Revenue: 54600  Cumulative average 51322.5 best score: 57500 epsilon 0.59 steps 41688\n",
      "Episode: 217 Total Revenue: 52700  Cumulative average 51328.8 best score: 57500 epsilon 0.59 steps 41881\n",
      "Episode: 218 Total Revenue: 54450  Cumulative average 51343.1 best score: 57500 epsilon 0.58 steps 42074\n",
      "Episode: 219 Total Revenue: 54450  Cumulative average 51357.3 best score: 57500 epsilon 0.58 steps 42267\n",
      "Episode: 220 Total Revenue: 52950  Cumulative average 51364.5 best score: 57500 epsilon 0.58 steps 42460\n",
      "Episode: 221 Total Revenue: 53550  Cumulative average 51374.4 best score: 57500 epsilon 0.58 steps 42653\n",
      "Episode: 222 Total Revenue: 54350  Cumulative average 51387.8 best score: 57500 epsilon 0.58 steps 42846\n",
      "Episode: 223 Total Revenue: 55050  Cumulative average 51404.3 best score: 57500 epsilon 0.57 steps 43039\n",
      "Episode: 224 Total Revenue: 53000  Cumulative average 51411.4 best score: 57500 epsilon 0.57 steps 43232\n",
      "Episode: 225 Total Revenue: 55350  Cumulative average 51428.9 best score: 57500 epsilon 0.57 steps 43425\n",
      "Episode: 226 Total Revenue: 52600  Cumulative average 51434.1 best score: 57500 epsilon 0.57 steps 43618\n",
      "Episode: 227 Total Revenue: 54600  Cumulative average 51448.0 best score: 57500 epsilon 0.57 steps 43811\n",
      "Episode: 228 Total Revenue: 53200  Cumulative average 51455.7 best score: 57500 epsilon 0.57 steps 44004\n",
      "Episode: 229 Total Revenue: 55250  Cumulative average 51472.3 best score: 57500 epsilon 0.56 steps 44197\n",
      "Episode: 230 Total Revenue: 54500  Cumulative average 51485.4 best score: 57500 epsilon 0.56 steps 44390\n",
      "Episode: 231 Total Revenue: 53050  Cumulative average 51492.2 best score: 57500 epsilon 0.56 steps 44583\n",
      "Episode: 232 Total Revenue: 53200  Cumulative average 51499.6 best score: 57500 epsilon 0.56 steps 44776\n",
      "Episode: 233 Total Revenue: 52800  Cumulative average 51505.2 best score: 57500 epsilon 0.56 steps 44969\n",
      "Episode: 234 Total Revenue: 52550  Cumulative average 51509.6 best score: 57500 epsilon 0.55 steps 45162\n",
      "Episode: 235 Total Revenue: 54800  Cumulative average 51523.6 best score: 57500 epsilon 0.55 steps 45355\n",
      "Episode: 236 Total Revenue: 54500  Cumulative average 51536.2 best score: 57500 epsilon 0.55 steps 45548\n",
      "Episode: 237 Total Revenue: 54400  Cumulative average 51548.3 best score: 57500 epsilon 0.55 steps 45741\n",
      "Episode: 238 Total Revenue: 56100  Cumulative average 51567.4 best score: 57500 epsilon 0.55 steps 45934\n",
      "Episode: 239 Total Revenue: 54050  Cumulative average 51577.8 best score: 57500 epsilon 0.54 steps 46127\n",
      "Episode: 240 Total Revenue: 54350  Cumulative average 51589.4 best score: 57500 epsilon 0.54 steps 46320\n",
      "Episode: 241 Total Revenue: 54650  Cumulative average 51602.1 best score: 57500 epsilon 0.54 steps 46513\n",
      "Episode: 242 Total Revenue: 53250  Cumulative average 51608.9 best score: 57500 epsilon 0.54 steps 46706\n",
      "Episode: 243 Total Revenue: 54050  Cumulative average 51618.9 best score: 57500 epsilon 0.54 steps 46899\n",
      "Episode: 244 Total Revenue: 52000  Cumulative average 51620.5 best score: 57500 epsilon 0.53 steps 47092\n",
      "Episode: 245 Total Revenue: 50600  Cumulative average 51616.3 best score: 57500 epsilon 0.53 steps 47285\n",
      "Episode: 246 Total Revenue: 52550  Cumulative average 51620.1 best score: 57500 epsilon 0.53 steps 47478\n",
      "Episode: 247 Total Revenue: 52300  Cumulative average 51622.9 best score: 57500 epsilon 0.53 steps 47671\n",
      "Episode: 248 Total Revenue: 54550  Cumulative average 51634.7 best score: 57500 epsilon 0.53 steps 47864\n",
      "Episode: 249 Total Revenue: 52550  Cumulative average 51638.4 best score: 57500 epsilon 0.52 steps 48057\n",
      "Episode: 250 Total Revenue: 53100  Cumulative average 51644.2 best score: 57500 epsilon 0.52 steps 48250\n",
      "Episode: 251 Total Revenue: 53800  Cumulative average 51652.8 best score: 57500 epsilon 0.52 steps 48443\n",
      "Episode: 252 Total Revenue: 52900  Cumulative average 51657.7 best score: 57500 epsilon 0.52 steps 48636\n",
      "Episode: 253 Total Revenue: 54750  Cumulative average 51670.0 best score: 57500 epsilon 0.52 steps 48829\n",
      "Episode: 254 Total Revenue: 54700  Cumulative average 51681.9 best score: 57500 epsilon 0.51 steps 49022\n",
      "Episode: 255 Total Revenue: 51550  Cumulative average 51681.4 best score: 57500 epsilon 0.51 steps 49215\n",
      "Episode: 256 Total Revenue: 52600  Cumulative average 51685.0 best score: 57500 epsilon 0.51 steps 49408\n",
      "Episode: 257 Total Revenue: 53500  Cumulative average 51692.0 best score: 57500 epsilon 0.51 steps 49601\n",
      "Episode: 258 Total Revenue: 50850  Cumulative average 51688.8 best score: 57500 epsilon 0.51 steps 49794\n",
      "Episode: 259 Total Revenue: 53200  Cumulative average 51694.6 best score: 57500 epsilon 0.51 steps 49987\n",
      "Episode: 260 Total Revenue: 53300  Cumulative average 51700.8 best score: 57500 epsilon 0.50 steps 50180\n",
      "Episode: 261 Total Revenue: 51900  Cumulative average 51701.5 best score: 57500 epsilon 0.50 steps 50373\n",
      "Episode: 262 Total Revenue: 52050  Cumulative average 51702.9 best score: 57500 epsilon 0.50 steps 50566\n",
      "Episode: 263 Total Revenue: 49600  Cumulative average 51694.9 best score: 57500 epsilon 0.50 steps 50759\n",
      "Episode: 264 Total Revenue: 52750  Cumulative average 51698.9 best score: 57500 epsilon 0.50 steps 50952\n",
      "Episode: 265 Total Revenue: 52100  Cumulative average 51700.4 best score: 57500 epsilon 0.49 steps 51145\n",
      "Episode: 266 Total Revenue: 53700  Cumulative average 51707.9 best score: 57500 epsilon 0.49 steps 51338\n",
      "Episode: 267 Total Revenue: 53350  Cumulative average 51714.0 best score: 57500 epsilon 0.49 steps 51531\n",
      "Episode: 268 Total Revenue: 53700  Cumulative average 51721.5 best score: 57500 epsilon 0.49 steps 51724\n",
      "Episode: 269 Total Revenue: 51750  Cumulative average 51721.6 best score: 57500 epsilon 0.49 steps 51917\n",
      "Episode: 270 Total Revenue: 55100  Cumulative average 51734.1 best score: 57500 epsilon 0.48 steps 52110\n",
      "Episode: 271 Total Revenue: 52000  Cumulative average 51735.1 best score: 57500 epsilon 0.48 steps 52303\n",
      "Episode: 272 Total Revenue: 52400  Cumulative average 51737.5 best score: 57500 epsilon 0.48 steps 52496\n",
      "Episode: 273 Total Revenue: 54200  Cumulative average 51746.5 best score: 57500 epsilon 0.48 steps 52689\n",
      "Episode: 274 Total Revenue: 55500  Cumulative average 51760.2 best score: 57500 epsilon 0.48 steps 52882\n",
      "Episode: 275 Total Revenue: 52100  Cumulative average 51761.5 best score: 57500 epsilon 0.47 steps 53075\n",
      "Episode: 276 Total Revenue: 57100  Cumulative average 51780.8 best score: 57500 epsilon 0.47 steps 53268\n",
      "Episode: 277 Total Revenue: 54750  Cumulative average 51791.5 best score: 57500 epsilon 0.47 steps 53461\n",
      "Episode: 278 Total Revenue: 54250  Cumulative average 51800.4 best score: 57500 epsilon 0.47 steps 53654\n",
      "Episode: 279 Total Revenue: 50600  Cumulative average 51796.1 best score: 57500 epsilon 0.47 steps 53847\n",
      "Episode: 280 Total Revenue: 52450  Cumulative average 51798.4 best score: 57500 epsilon 0.46 steps 54040\n",
      "Episode: 281 Total Revenue: 53700  Cumulative average 51805.2 best score: 57500 epsilon 0.46 steps 54233\n",
      "Episode: 282 Total Revenue: 55000  Cumulative average 51816.5 best score: 57500 epsilon 0.46 steps 54426\n",
      "Episode: 283 Total Revenue: 53550  Cumulative average 51822.6 best score: 57500 epsilon 0.46 steps 54619\n",
      "Episode: 284 Total Revenue: 53000  Cumulative average 51826.8 best score: 57500 epsilon 0.46 steps 54812\n",
      "Episode: 285 Total Revenue: 52100  Cumulative average 51827.7 best score: 57500 epsilon 0.46 steps 55005\n",
      "Episode: 286 Total Revenue: 52100  Cumulative average 51828.7 best score: 57500 epsilon 0.45 steps 55198\n",
      "Episode: 287 Total Revenue: 50650  Cumulative average 51824.6 best score: 57500 epsilon 0.45 steps 55391\n",
      "Episode: 288 Total Revenue: 54550  Cumulative average 51834.0 best score: 57500 epsilon 0.45 steps 55584\n",
      "Episode: 289 Total Revenue: 52650  Cumulative average 51836.9 best score: 57500 epsilon 0.45 steps 55777\n",
      "Episode: 290 Total Revenue: 53650  Cumulative average 51843.1 best score: 57500 epsilon 0.45 steps 55970\n",
      "Episode: 291 Total Revenue: 52650  Cumulative average 51845.9 best score: 57500 epsilon 0.44 steps 56163\n",
      "Episode: 292 Total Revenue: 52600  Cumulative average 51848.5 best score: 57500 epsilon 0.44 steps 56356\n",
      "Episode: 293 Total Revenue: 55050  Cumulative average 51859.4 best score: 57500 epsilon 0.44 steps 56549\n",
      "Episode: 294 Total Revenue: 50800  Cumulative average 51855.8 best score: 57500 epsilon 0.44 steps 56742\n",
      "Episode: 295 Total Revenue: 54000  Cumulative average 51863.1 best score: 57500 epsilon 0.44 steps 56935\n",
      "Episode: 296 Total Revenue: 54450  Cumulative average 51871.8 best score: 57500 epsilon 0.43 steps 57128\n",
      "Episode: 297 Total Revenue: 53600  Cumulative average 51877.6 best score: 57500 epsilon 0.43 steps 57321\n",
      "Episode: 298 Total Revenue: 51400  Cumulative average 51876.0 best score: 57500 epsilon 0.43 steps 57514\n",
      "Episode: 299 Total Revenue: 52300  Cumulative average 51877.4 best score: 57500 epsilon 0.43 steps 57707\n",
      "Episode: 300 Total Revenue: 50300  Cumulative average 51872.2 best score: 57500 epsilon 0.43 steps 57900\n",
      "Episode: 301 Total Revenue: 53650  Cumulative average 51878.1 best score: 57500 epsilon 0.42 steps 58093\n",
      "Episode: 302 Total Revenue: 52250  Cumulative average 51879.3 best score: 57500 epsilon 0.42 steps 58286\n",
      "Episode: 303 Total Revenue: 53500  Cumulative average 51884.7 best score: 57500 epsilon 0.42 steps 58479\n",
      "Episode: 304 Total Revenue: 52450  Cumulative average 51886.5 best score: 57500 epsilon 0.42 steps 58672\n",
      "Episode: 305 Total Revenue: 53400  Cumulative average 51891.5 best score: 57500 epsilon 0.42 steps 58865\n",
      "Episode: 306 Total Revenue: 50900  Cumulative average 51888.2 best score: 57500 epsilon 0.41 steps 59058\n",
      "Episode: 307 Total Revenue: 52900  Cumulative average 51891.5 best score: 57500 epsilon 0.41 steps 59251\n",
      "Episode: 308 Total Revenue: 52800  Cumulative average 51894.5 best score: 57500 epsilon 0.41 steps 59444\n",
      "Episode: 309 Total Revenue: 51250  Cumulative average 51892.4 best score: 57500 epsilon 0.41 steps 59637\n",
      "Episode: 310 Total Revenue: 51500  Cumulative average 51891.1 best score: 57500 epsilon 0.41 steps 59830\n",
      "Episode: 311 Total Revenue: 54150  Cumulative average 51898.4 best score: 57500 epsilon 0.40 steps 60023\n",
      "Episode: 312 Total Revenue: 52900  Cumulative average 51901.6 best score: 57500 epsilon 0.40 steps 60216\n",
      "Episode: 313 Total Revenue: 53950  Cumulative average 51908.1 best score: 57500 epsilon 0.40 steps 60409\n",
      "Episode: 314 Total Revenue: 52350  Cumulative average 51909.6 best score: 57500 epsilon 0.40 steps 60602\n",
      "Episode: 315 Total Revenue: 50750  Cumulative average 51905.9 best score: 57500 epsilon 0.40 steps 60795\n",
      "Episode: 316 Total Revenue: 52800  Cumulative average 51908.7 best score: 57500 epsilon 0.40 steps 60988\n",
      "Episode: 317 Total Revenue: 53500  Cumulative average 51913.7 best score: 57500 epsilon 0.39 steps 61181\n",
      "Episode: 318 Total Revenue: 54000  Cumulative average 51920.3 best score: 57500 epsilon 0.39 steps 61374\n",
      "Episode: 319 Total Revenue: 53900  Cumulative average 51926.5 best score: 57500 epsilon 0.39 steps 61567\n",
      "Episode: 320 Total Revenue: 51100  Cumulative average 51923.9 best score: 57500 epsilon 0.39 steps 61760\n",
      "Episode: 321 Total Revenue: 52000  Cumulative average 51924.1 best score: 57500 epsilon 0.39 steps 61953\n",
      "Episode: 322 Total Revenue: 53200  Cumulative average 51928.1 best score: 57500 epsilon 0.38 steps 62146\n",
      "Episode: 323 Total Revenue: 51550  Cumulative average 51926.9 best score: 57500 epsilon 0.38 steps 62339\n",
      "Episode: 324 Total Revenue: 53250  Cumulative average 51931.0 best score: 57500 epsilon 0.38 steps 62532\n",
      "Episode: 325 Total Revenue: 52600  Cumulative average 51933.1 best score: 57500 epsilon 0.38 steps 62725\n",
      "Episode: 326 Total Revenue: 52900  Cumulative average 51936.0 best score: 57500 epsilon 0.38 steps 62918\n",
      "Episode: 327 Total Revenue: 52250  Cumulative average 51937.0 best score: 57500 epsilon 0.37 steps 63111\n",
      "Episode: 328 Total Revenue: 54550  Cumulative average 51945.0 best score: 57500 epsilon 0.37 steps 63304\n",
      "Episode: 329 Total Revenue: 54900  Cumulative average 51954.0 best score: 57500 epsilon 0.37 steps 63497\n",
      "Episode: 330 Total Revenue: 49800  Cumulative average 51947.4 best score: 57500 epsilon 0.37 steps 63690\n",
      "Episode: 331 Total Revenue: 51800  Cumulative average 51947.0 best score: 57500 epsilon 0.37 steps 63883\n",
      "Episode: 332 Total Revenue: 51100  Cumulative average 51944.4 best score: 57500 epsilon 0.36 steps 64076\n",
      "Episode: 333 Total Revenue: 51800  Cumulative average 51944.0 best score: 57500 epsilon 0.36 steps 64269\n",
      "Episode: 334 Total Revenue: 53250  Cumulative average 51947.9 best score: 57500 epsilon 0.36 steps 64462\n",
      "Episode: 335 Total Revenue: 52200  Cumulative average 51948.7 best score: 57500 epsilon 0.36 steps 64655\n",
      "Episode: 336 Total Revenue: 51300  Cumulative average 51946.7 best score: 57500 epsilon 0.36 steps 64848\n",
      "Episode: 337 Total Revenue: 53350  Cumulative average 51950.9 best score: 57500 epsilon 0.35 steps 65041\n",
      "Episode: 338 Total Revenue: 52750  Cumulative average 51953.3 best score: 57500 epsilon 0.35 steps 65234\n",
      "Episode: 339 Total Revenue: 52250  Cumulative average 51954.1 best score: 57500 epsilon 0.35 steps 65427\n",
      "Episode: 340 Total Revenue: 54200  Cumulative average 51960.7 best score: 57500 epsilon 0.35 steps 65620\n",
      "Episode: 341 Total Revenue: 52300  Cumulative average 51961.7 best score: 57500 epsilon 0.35 steps 65813\n",
      "Episode: 342 Total Revenue: 53600  Cumulative average 51966.5 best score: 57500 epsilon 0.35 steps 66006\n",
      "Episode: 343 Total Revenue: 55100  Cumulative average 51975.7 best score: 57500 epsilon 0.34 steps 66199\n",
      "Episode: 344 Total Revenue: 50900  Cumulative average 51972.5 best score: 57500 epsilon 0.34 steps 66392\n",
      "Episode: 345 Total Revenue: 51300  Cumulative average 51970.6 best score: 57500 epsilon 0.34 steps 66585\n",
      "Episode: 346 Total Revenue: 50800  Cumulative average 51967.2 best score: 57500 epsilon 0.34 steps 66778\n",
      "Episode: 347 Total Revenue: 50400  Cumulative average 51962.7 best score: 57500 epsilon 0.34 steps 66971\n",
      "Episode: 348 Total Revenue: 51250  Cumulative average 51960.6 best score: 57500 epsilon 0.33 steps 67164\n",
      "Episode: 349 Total Revenue: 51500  Cumulative average 51959.3 best score: 57500 epsilon 0.33 steps 67357\n",
      "Episode: 350 Total Revenue: 55950  Cumulative average 51970.7 best score: 57500 epsilon 0.33 steps 67550\n",
      "Episode: 351 Total Revenue: 50650  Cumulative average 51967.0 best score: 57500 epsilon 0.33 steps 67743\n",
      "Episode: 352 Total Revenue: 50650  Cumulative average 51963.2 best score: 57500 epsilon 0.33 steps 67936\n",
      "Episode: 353 Total Revenue: 51700  Cumulative average 51962.5 best score: 57500 epsilon 0.32 steps 68129\n",
      "Episode: 354 Total Revenue: 52950  Cumulative average 51965.3 best score: 57500 epsilon 0.32 steps 68322\n",
      "Episode: 355 Total Revenue: 51600  Cumulative average 51964.2 best score: 57500 epsilon 0.32 steps 68515\n",
      "Episode: 356 Total Revenue: 51650  Cumulative average 51963.3 best score: 57500 epsilon 0.32 steps 68708\n",
      "Episode: 357 Total Revenue: 52050  Cumulative average 51963.6 best score: 57500 epsilon 0.32 steps 68901\n",
      "Episode: 358 Total Revenue: 52600  Cumulative average 51965.4 best score: 57500 epsilon 0.31 steps 69094\n",
      "Episode: 359 Total Revenue: 51150  Cumulative average 51963.1 best score: 57500 epsilon 0.31 steps 69287\n",
      "Episode: 360 Total Revenue: 51100  Cumulative average 51960.7 best score: 57500 epsilon 0.31 steps 69480\n",
      "Episode: 361 Total Revenue: 51700  Cumulative average 51960.0 best score: 57500 epsilon 0.31 steps 69673\n",
      "Episode: 362 Total Revenue: 51300  Cumulative average 51958.1 best score: 57500 epsilon 0.31 steps 69866\n",
      "Episode: 363 Total Revenue: 51200  Cumulative average 51956.1 best score: 57500 epsilon 0.30 steps 70059\n",
      "Episode: 364 Total Revenue: 53500  Cumulative average 51960.3 best score: 57500 epsilon 0.30 steps 70252\n",
      "Episode: 365 Total Revenue: 51150  Cumulative average 51958.1 best score: 57500 epsilon 0.30 steps 70445\n",
      "Episode: 366 Total Revenue: 54000  Cumulative average 51963.7 best score: 57500 epsilon 0.30 steps 70638\n",
      "Episode: 367 Total Revenue: 54850  Cumulative average 51971.5 best score: 57500 epsilon 0.30 steps 70831\n",
      "Episode: 368 Total Revenue: 51700  Cumulative average 51970.8 best score: 57500 epsilon 0.29 steps 71024\n",
      "Episode: 369 Total Revenue: 51250  Cumulative average 51968.8 best score: 57500 epsilon 0.29 steps 71217\n",
      "Episode: 370 Total Revenue: 51750  Cumulative average 51968.2 best score: 57500 epsilon 0.29 steps 71410\n",
      "Episode: 371 Total Revenue: 51200  Cumulative average 51966.2 best score: 57500 epsilon 0.29 steps 71603\n",
      "Episode: 372 Total Revenue: 53900  Cumulative average 51971.4 best score: 57500 epsilon 0.29 steps 71796\n",
      "Episode: 373 Total Revenue: 51850  Cumulative average 51971.0 best score: 57500 epsilon 0.29 steps 71989\n",
      "Episode: 374 Total Revenue: 53500  Cumulative average 51975.1 best score: 57500 epsilon 0.28 steps 72182\n",
      "Episode: 375 Total Revenue: 52500  Cumulative average 51976.5 best score: 57500 epsilon 0.28 steps 72375\n",
      "Episode: 376 Total Revenue: 52450  Cumulative average 51977.8 best score: 57500 epsilon 0.28 steps 72568\n",
      "Episode: 377 Total Revenue: 51400  Cumulative average 51976.3 best score: 57500 epsilon 0.28 steps 72761\n",
      "Episode: 378 Total Revenue: 52350  Cumulative average 51977.2 best score: 57500 epsilon 0.28 steps 72954\n",
      "Episode: 379 Total Revenue: 52450  Cumulative average 51978.5 best score: 57500 epsilon 0.27 steps 73147\n",
      "Episode: 380 Total Revenue: 53100  Cumulative average 51981.4 best score: 57500 epsilon 0.27 steps 73340\n",
      "Episode: 381 Total Revenue: 50550  Cumulative average 51977.7 best score: 57500 epsilon 0.27 steps 73533\n",
      "Episode: 382 Total Revenue: 52700  Cumulative average 51979.6 best score: 57500 epsilon 0.27 steps 73726\n",
      "Episode: 383 Total Revenue: 54350  Cumulative average 51985.8 best score: 57500 epsilon 0.27 steps 73919\n",
      "Episode: 384 Total Revenue: 55050  Cumulative average 51993.8 best score: 57500 epsilon 0.26 steps 74112\n",
      "Episode: 385 Total Revenue: 52850  Cumulative average 51996.0 best score: 57500 epsilon 0.26 steps 74305\n",
      "Episode: 386 Total Revenue: 51950  Cumulative average 51995.9 best score: 57500 epsilon 0.26 steps 74498\n",
      "Episode: 387 Total Revenue: 52300  Cumulative average 51996.6 best score: 57500 epsilon 0.26 steps 74691\n",
      "Episode: 388 Total Revenue: 49000  Cumulative average 51988.9 best score: 57500 epsilon 0.26 steps 74884\n",
      "Episode: 389 Total Revenue: 51600  Cumulative average 51987.9 best score: 57500 epsilon 0.25 steps 75077\n",
      "Episode: 390 Total Revenue: 51050  Cumulative average 51985.5 best score: 57500 epsilon 0.25 steps 75270\n",
      "Episode: 391 Total Revenue: 52050  Cumulative average 51985.7 best score: 57500 epsilon 0.25 steps 75463\n",
      "Episode: 392 Total Revenue: 50700  Cumulative average 51982.4 best score: 57500 epsilon 0.25 steps 75656\n",
      "Episode: 393 Total Revenue: 52650  Cumulative average 51984.1 best score: 57500 epsilon 0.25 steps 75849\n",
      "Episode: 394 Total Revenue: 53650  Cumulative average 51988.3 best score: 57500 epsilon 0.24 steps 76042\n",
      "Episode: 395 Total Revenue: 50200  Cumulative average 51983.8 best score: 57500 epsilon 0.24 steps 76235\n",
      "Episode: 396 Total Revenue: 51850  Cumulative average 51983.5 best score: 57500 epsilon 0.24 steps 76428\n",
      "Episode: 397 Total Revenue: 51250  Cumulative average 51981.6 best score: 57500 epsilon 0.24 steps 76621\n",
      "Episode: 398 Total Revenue: 51400  Cumulative average 51980.2 best score: 57500 epsilon 0.24 steps 76814\n",
      "Episode: 399 Total Revenue: 52400  Cumulative average 51981.2 best score: 57500 epsilon 0.24 steps 77007\n",
      "Episode: 400 Total Revenue: 51250  Cumulative average 51979.4 best score: 57500 epsilon 0.23 steps 77200\n",
      "Episode: 401 Total Revenue: 52600  Cumulative average 51980.9 best score: 57500 epsilon 0.23 steps 77393\n",
      "Episode: 402 Total Revenue: 50400  Cumulative average 51977.0 best score: 57500 epsilon 0.23 steps 77586\n",
      "Episode: 403 Total Revenue: 52150  Cumulative average 51977.4 best score: 57500 epsilon 0.23 steps 77779\n",
      "Episode: 404 Total Revenue: 50450  Cumulative average 51973.6 best score: 57500 epsilon 0.23 steps 77972\n",
      "Episode: 405 Total Revenue: 53050  Cumulative average 51976.3 best score: 57500 epsilon 0.22 steps 78165\n",
      "Episode: 406 Total Revenue: 49900  Cumulative average 51971.2 best score: 57500 epsilon 0.22 steps 78358\n",
      "Episode: 407 Total Revenue: 53450  Cumulative average 51974.8 best score: 57500 epsilon 0.22 steps 78551\n",
      "Episode: 408 Total Revenue: 50850  Cumulative average 51972.1 best score: 57500 epsilon 0.22 steps 78744\n",
      "Episode: 409 Total Revenue: 52900  Cumulative average 51974.3 best score: 57500 epsilon 0.22 steps 78937\n",
      "Episode: 410 Total Revenue: 51350  Cumulative average 51972.8 best score: 57500 epsilon 0.21 steps 79130\n",
      "Episode: 411 Total Revenue: 52500  Cumulative average 51974.1 best score: 57500 epsilon 0.21 steps 79323\n",
      "Episode: 412 Total Revenue: 54050  Cumulative average 51979.1 best score: 57500 epsilon 0.21 steps 79516\n",
      "Episode: 413 Total Revenue: 51850  Cumulative average 51978.8 best score: 57500 epsilon 0.21 steps 79709\n",
      "Episode: 414 Total Revenue: 51650  Cumulative average 51978.0 best score: 57500 epsilon 0.21 steps 79902\n",
      "Episode: 415 Total Revenue: 49950  Cumulative average 51973.1 best score: 57500 epsilon 0.20 steps 80095\n",
      "Episode: 416 Total Revenue: 53750  Cumulative average 51977.4 best score: 57500 epsilon 0.20 steps 80288\n",
      "Episode: 417 Total Revenue: 52900  Cumulative average 51979.6 best score: 57500 epsilon 0.20 steps 80481\n",
      "Episode: 418 Total Revenue: 53600  Cumulative average 51983.5 best score: 57500 epsilon 0.20 steps 80674\n",
      "Episode: 419 Total Revenue: 49600  Cumulative average 51977.8 best score: 57500 epsilon 0.20 steps 80867\n",
      "Episode: 420 Total Revenue: 50900  Cumulative average 51975.2 best score: 57500 epsilon 0.19 steps 81060\n",
      "Episode: 421 Total Revenue: 51200  Cumulative average 51973.4 best score: 57500 epsilon 0.19 steps 81253\n",
      "Episode: 422 Total Revenue: 51300  Cumulative average 51971.8 best score: 57500 epsilon 0.19 steps 81446\n",
      "Episode: 423 Total Revenue: 49400  Cumulative average 51965.7 best score: 57500 epsilon 0.19 steps 81639\n",
      "Episode: 424 Total Revenue: 52500  Cumulative average 51967.0 best score: 57500 epsilon 0.19 steps 81832\n",
      "Episode: 425 Total Revenue: 50350  Cumulative average 51963.2 best score: 57500 epsilon 0.18 steps 82025\n",
      "Episode: 426 Total Revenue: 50950  Cumulative average 51960.8 best score: 57500 epsilon 0.18 steps 82218\n",
      "Episode: 427 Total Revenue: 52050  Cumulative average 51961.0 best score: 57500 epsilon 0.18 steps 82411\n",
      "Episode: 428 Total Revenue: 49900  Cumulative average 51956.2 best score: 57500 epsilon 0.18 steps 82604\n",
      "Episode: 429 Total Revenue: 51300  Cumulative average 51954.7 best score: 57500 epsilon 0.18 steps 82797\n",
      "Episode: 430 Total Revenue: 54450  Cumulative average 51960.5 best score: 57500 epsilon 0.18 steps 82990\n",
      "Episode: 431 Total Revenue: 52400  Cumulative average 51961.5 best score: 57500 epsilon 0.17 steps 83183\n",
      "Episode: 432 Total Revenue: 57150  Cumulative average 51973.5 best score: 57500 epsilon 0.17 steps 83376\n",
      "Episode: 433 Total Revenue: 53500  Cumulative average 51977.0 best score: 57500 epsilon 0.17 steps 83569\n",
      "Episode: 434 Total Revenue: 50450  Cumulative average 51973.5 best score: 57500 epsilon 0.17 steps 83762\n",
      "Episode: 435 Total Revenue: 54200  Cumulative average 51978.6 best score: 57500 epsilon 0.17 steps 83955\n",
      "Episode: 436 Total Revenue: 49200  Cumulative average 51972.2 best score: 57500 epsilon 0.16 steps 84148\n",
      "Episode: 437 Total Revenue: 51850  Cumulative average 51972.0 best score: 57500 epsilon 0.16 steps 84341\n",
      "Episode: 438 Total Revenue: 52900  Cumulative average 51974.1 best score: 57500 epsilon 0.16 steps 84534\n",
      "Episode: 439 Total Revenue: 52700  Cumulative average 51975.7 best score: 57500 epsilon 0.16 steps 84727\n",
      "Episode: 440 Total Revenue: 50900  Cumulative average 51973.3 best score: 57500 epsilon 0.16 steps 84920\n",
      "Episode: 441 Total Revenue: 52000  Cumulative average 51973.4 best score: 57500 epsilon 0.15 steps 85113\n",
      "Episode: 442 Total Revenue: 50800  Cumulative average 51970.7 best score: 57500 epsilon 0.15 steps 85306\n",
      "Episode: 443 Total Revenue: 53050  Cumulative average 51973.1 best score: 57500 epsilon 0.15 steps 85499\n",
      "Episode: 444 Total Revenue: 50600  Cumulative average 51970.0 best score: 57500 epsilon 0.15 steps 85692\n",
      "Episode: 445 Total Revenue: 50100  Cumulative average 51965.8 best score: 57500 epsilon 0.15 steps 85885\n",
      "Episode: 446 Total Revenue: 53350  Cumulative average 51968.9 best score: 57500 epsilon 0.14 steps 86078\n",
      "Episode: 447 Total Revenue: 50950  Cumulative average 51966.7 best score: 57500 epsilon 0.14 steps 86271\n",
      "Episode: 448 Total Revenue: 50600  Cumulative average 51963.6 best score: 57500 epsilon 0.14 steps 86464\n",
      "Episode: 449 Total Revenue: 53050  Cumulative average 51966.0 best score: 57500 epsilon 0.14 steps 86657\n",
      "Episode: 450 Total Revenue: 54700  Cumulative average 51972.1 best score: 57500 epsilon 0.14 steps 86850\n",
      "Episode: 451 Total Revenue: 51450  Cumulative average 51971.0 best score: 57500 epsilon 0.13 steps 87043\n",
      "Episode: 452 Total Revenue: 54950  Cumulative average 51977.5 best score: 57500 epsilon 0.13 steps 87236\n",
      "Episode: 453 Total Revenue: 51700  Cumulative average 51976.9 best score: 57500 epsilon 0.13 steps 87429\n",
      "Episode: 454 Total Revenue: 52000  Cumulative average 51977.0 best score: 57500 epsilon 0.13 steps 87622\n",
      "Episode: 455 Total Revenue: 52900  Cumulative average 51979.0 best score: 57500 epsilon 0.13 steps 87815\n",
      "Episode: 456 Total Revenue: 50450  Cumulative average 51975.7 best score: 57500 epsilon 0.13 steps 88008\n",
      "Episode: 457 Total Revenue: 49450  Cumulative average 51970.1 best score: 57500 epsilon 0.12 steps 88201\n",
      "Episode: 458 Total Revenue: 53750  Cumulative average 51974.0 best score: 57500 epsilon 0.12 steps 88394\n",
      "Episode: 459 Total Revenue: 54100  Cumulative average 51978.6 best score: 57500 epsilon 0.12 steps 88587\n",
      "Episode: 460 Total Revenue: 50400  Cumulative average 51975.2 best score: 57500 epsilon 0.12 steps 88780\n",
      "Episode: 461 Total Revenue: 50650  Cumulative average 51972.3 best score: 57500 epsilon 0.12 steps 88973\n",
      "Episode: 462 Total Revenue: 53800  Cumulative average 51976.3 best score: 57500 epsilon 0.11 steps 89166\n",
      "Episode: 463 Total Revenue: 49900  Cumulative average 51971.8 best score: 57500 epsilon 0.11 steps 89359\n",
      "Episode: 464 Total Revenue: 53800  Cumulative average 51975.8 best score: 57500 epsilon 0.11 steps 89552\n",
      "Episode: 465 Total Revenue: 53450  Cumulative average 51978.9 best score: 57500 epsilon 0.11 steps 89745\n",
      "Episode: 466 Total Revenue: 51150  Cumulative average 51977.1 best score: 57500 epsilon 0.11 steps 89938\n",
      "Episode: 467 Total Revenue: 52900  Cumulative average 51979.1 best score: 57500 epsilon 0.10 steps 90131\n",
      "Episode: 468 Total Revenue: 54000  Cumulative average 51983.4 best score: 57500 epsilon 0.10 steps 90324\n",
      "Episode: 469 Total Revenue: 52100  Cumulative average 51983.7 best score: 57500 epsilon 0.10 steps 90517\n",
      "Episode: 470 Total Revenue: 50200  Cumulative average 51979.9 best score: 57500 epsilon 0.10 steps 90710\n",
      "Episode: 471 Total Revenue: 53050  Cumulative average 51982.2 best score: 57500 epsilon 0.10 steps 90903\n",
      "Episode: 472 Total Revenue: 52500  Cumulative average 51983.3 best score: 57500 epsilon 0.10 steps 91096\n",
      "Episode: 473 Total Revenue: 50700  Cumulative average 51980.5 best score: 57500 epsilon 0.10 steps 91289\n",
      "Episode: 474 Total Revenue: 53600  Cumulative average 51984.0 best score: 57500 epsilon 0.10 steps 91482\n",
      "Episode: 475 Total Revenue: 49650  Cumulative average 51979.1 best score: 57500 epsilon 0.10 steps 91675\n",
      "Episode: 476 Total Revenue: 51450  Cumulative average 51977.9 best score: 57500 epsilon 0.10 steps 91868\n",
      "Episode: 477 Total Revenue: 50800  Cumulative average 51975.5 best score: 57500 epsilon 0.10 steps 92061\n",
      "Episode: 478 Total Revenue: 52550  Cumulative average 51976.7 best score: 57500 epsilon 0.10 steps 92254\n",
      "Episode: 479 Total Revenue: 53500  Cumulative average 51979.9 best score: 57500 epsilon 0.10 steps 92447\n",
      "Episode: 480 Total Revenue: 51600  Cumulative average 51979.1 best score: 57500 epsilon 0.10 steps 92640\n",
      "Episode: 481 Total Revenue: 51550  Cumulative average 51978.2 best score: 57500 epsilon 0.10 steps 92833\n",
      "Episode: 482 Total Revenue: 51800  Cumulative average 51977.8 best score: 57500 epsilon 0.10 steps 93026\n",
      "Episode: 483 Total Revenue: 53100  Cumulative average 51980.1 best score: 57500 epsilon 0.10 steps 93219\n",
      "Episode: 484 Total Revenue: 51950  Cumulative average 51980.1 best score: 57500 epsilon 0.10 steps 93412\n",
      "Episode: 485 Total Revenue: 50800  Cumulative average 51977.6 best score: 57500 epsilon 0.10 steps 93605\n",
      "Episode: 486 Total Revenue: 52900  Cumulative average 51979.5 best score: 57500 epsilon 0.10 steps 93798\n",
      "Episode: 487 Total Revenue: 50050  Cumulative average 51975.6 best score: 57500 epsilon 0.10 steps 93991\n",
      "Episode: 488 Total Revenue: 50600  Cumulative average 51972.7 best score: 57500 epsilon 0.10 steps 94184\n",
      "Episode: 489 Total Revenue: 52050  Cumulative average 51972.9 best score: 57500 epsilon 0.10 steps 94377\n",
      "Episode: 490 Total Revenue: 52100  Cumulative average 51973.2 best score: 57500 epsilon 0.10 steps 94570\n",
      "Episode: 491 Total Revenue: 50750  Cumulative average 51970.7 best score: 57500 epsilon 0.10 steps 94763\n",
      "Episode: 492 Total Revenue: 50250  Cumulative average 51967.2 best score: 57500 epsilon 0.10 steps 94956\n",
      "Episode: 493 Total Revenue: 50700  Cumulative average 51964.6 best score: 57500 epsilon 0.10 steps 95149\n",
      "Episode: 494 Total Revenue: 52150  Cumulative average 51965.0 best score: 57500 epsilon 0.10 steps 95342\n",
      "Episode: 495 Total Revenue: 52000  Cumulative average 51965.1 best score: 57500 epsilon 0.10 steps 95535\n",
      "Episode: 496 Total Revenue: 50450  Cumulative average 51962.0 best score: 57500 epsilon 0.10 steps 95728\n",
      "Episode: 497 Total Revenue: 53550  Cumulative average 51965.2 best score: 57500 epsilon 0.10 steps 95921\n",
      "Episode: 498 Total Revenue: 54800  Cumulative average 51970.9 best score: 57500 epsilon 0.10 steps 96114\n",
      "Episode: 499 Total Revenue: 53200  Cumulative average 51973.3 best score: 57500 epsilon 0.10 steps 96307\n",
      "Episode: 500 Total Revenue: 52350  Cumulative average 51974.1 best score: 57500 epsilon 0.10 steps 96500\n",
      "Episode: 501 Total Revenue: 51800  Cumulative average 51973.8 best score: 57500 epsilon 0.10 steps 96693\n",
      "Episode: 502 Total Revenue: 50600  Cumulative average 51971.0 best score: 57500 epsilon 0.10 steps 96886\n",
      "Episode: 503 Total Revenue: 50550  Cumulative average 51968.2 best score: 57500 epsilon 0.10 steps 97079\n",
      "Episode: 504 Total Revenue: 51250  Cumulative average 51966.8 best score: 57500 epsilon 0.10 steps 97272\n",
      "Episode: 505 Total Revenue: 53150  Cumulative average 51969.1 best score: 57500 epsilon 0.10 steps 97465\n",
      "Episode: 506 Total Revenue: 52800  Cumulative average 51970.8 best score: 57500 epsilon 0.10 steps 97658\n",
      "Episode: 507 Total Revenue: 52350  Cumulative average 51971.5 best score: 57500 epsilon 0.10 steps 97851\n",
      "Episode: 508 Total Revenue: 51700  Cumulative average 51971.0 best score: 57500 epsilon 0.10 steps 98044\n",
      "Episode: 509 Total Revenue: 51650  Cumulative average 51970.3 best score: 57500 epsilon 0.10 steps 98237\n",
      "Episode: 510 Total Revenue: 50900  Cumulative average 51968.2 best score: 57500 epsilon 0.10 steps 98430\n",
      "Episode: 511 Total Revenue: 50000  Cumulative average 51964.4 best score: 57500 epsilon 0.10 steps 98623\n",
      "Episode: 512 Total Revenue: 52800  Cumulative average 51966.0 best score: 57500 epsilon 0.10 steps 98816\n",
      "Episode: 513 Total Revenue: 52550  Cumulative average 51967.2 best score: 57500 epsilon 0.10 steps 99009\n",
      "Episode: 514 Total Revenue: 50300  Cumulative average 51963.9 best score: 57500 epsilon 0.10 steps 99202\n",
      "Episode: 515 Total Revenue: 51650  Cumulative average 51963.3 best score: 57500 epsilon 0.10 steps 99395\n",
      "Episode: 516 Total Revenue: 51650  Cumulative average 51962.7 best score: 57500 epsilon 0.10 steps 99588\n",
      "Episode: 517 Total Revenue: 51650  Cumulative average 51962.1 best score: 57500 epsilon 0.10 steps 99781\n",
      "Episode: 518 Total Revenue: 52000  Cumulative average 51962.2 best score: 57500 epsilon 0.10 steps 99974\n",
      "Episode: 519 Total Revenue: 52500  Cumulative average 51963.2 best score: 57500 epsilon 0.10 steps 100167\n",
      "Episode: 520 Total Revenue: 52500  Cumulative average 51964.2 best score: 57500 epsilon 0.10 steps 100360\n",
      "Episode: 521 Total Revenue: 50150  Cumulative average 51960.7 best score: 57500 epsilon 0.10 steps 100553\n",
      "Episode: 522 Total Revenue: 51300  Cumulative average 51959.5 best score: 57500 epsilon 0.10 steps 100746\n",
      "Episode: 523 Total Revenue: 53100  Cumulative average 51961.7 best score: 57500 epsilon 0.10 steps 100939\n",
      "Episode: 524 Total Revenue: 53050  Cumulative average 51963.7 best score: 57500 epsilon 0.10 steps 101132\n",
      "Episode: 525 Total Revenue: 52300  Cumulative average 51964.4 best score: 57500 epsilon 0.10 steps 101325\n",
      "Episode: 526 Total Revenue: 49950  Cumulative average 51960.6 best score: 57500 epsilon 0.10 steps 101518\n",
      "Episode: 527 Total Revenue: 51750  Cumulative average 51960.2 best score: 57500 epsilon 0.10 steps 101711\n",
      "Episode: 528 Total Revenue: 51850  Cumulative average 51959.9 best score: 57500 epsilon 0.10 steps 101904\n",
      "Episode: 529 Total Revenue: 50750  Cumulative average 51957.7 best score: 57500 epsilon 0.10 steps 102097\n",
      "Episode: 530 Total Revenue: 51050  Cumulative average 51955.9 best score: 57500 epsilon 0.10 steps 102290\n",
      "Episode: 531 Total Revenue: 51700  Cumulative average 51955.5 best score: 57500 epsilon 0.10 steps 102483\n",
      "Episode: 532 Total Revenue: 50600  Cumulative average 51952.9 best score: 57500 epsilon 0.10 steps 102676\n",
      "Episode: 533 Total Revenue: 51400  Cumulative average 51951.9 best score: 57500 epsilon 0.10 steps 102869\n",
      "Episode: 534 Total Revenue: 52200  Cumulative average 51952.3 best score: 57500 epsilon 0.10 steps 103062\n",
      "Episode: 535 Total Revenue: 51800  Cumulative average 51952.1 best score: 57500 epsilon 0.10 steps 103255\n",
      "Episode: 536 Total Revenue: 50300  Cumulative average 51949.0 best score: 57500 epsilon 0.10 steps 103448\n",
      "Episode: 537 Total Revenue: 51350  Cumulative average 51947.9 best score: 57500 epsilon 0.10 steps 103641\n",
      "Episode: 538 Total Revenue: 51550  Cumulative average 51947.1 best score: 57500 epsilon 0.10 steps 103834\n",
      "Episode: 539 Total Revenue: 51700  Cumulative average 51946.7 best score: 57500 epsilon 0.10 steps 104027\n",
      "Episode: 540 Total Revenue: 53000  Cumulative average 51948.6 best score: 57500 epsilon 0.10 steps 104220\n",
      "Episode: 541 Total Revenue: 50700  Cumulative average 51946.3 best score: 57500 epsilon 0.10 steps 104413\n",
      "Episode: 542 Total Revenue: 48800  Cumulative average 51940.5 best score: 57500 epsilon 0.10 steps 104606\n",
      "Episode: 543 Total Revenue: 49450  Cumulative average 51935.9 best score: 57500 epsilon 0.10 steps 104799\n",
      "Episode: 544 Total Revenue: 54000  Cumulative average 51939.7 best score: 57500 epsilon 0.10 steps 104992\n",
      "Episode: 545 Total Revenue: 52950  Cumulative average 51941.6 best score: 57500 epsilon 0.10 steps 105185\n",
      "Episode: 546 Total Revenue: 50400  Cumulative average 51938.7 best score: 57500 epsilon 0.10 steps 105378\n",
      "Episode: 547 Total Revenue: 49900  Cumulative average 51935.0 best score: 57500 epsilon 0.10 steps 105571\n",
      "Episode: 548 Total Revenue: 50300  Cumulative average 51932.0 best score: 57500 epsilon 0.10 steps 105764\n",
      "Episode: 549 Total Revenue: 51950  Cumulative average 51932.1 best score: 57500 epsilon 0.10 steps 105957\n",
      "Episode: 550 Total Revenue: 53300  Cumulative average 51934.5 best score: 57500 epsilon 0.10 steps 106150\n",
      "Episode: 551 Total Revenue: 49300  Cumulative average 51929.8 best score: 57500 epsilon 0.10 steps 106343\n",
      "Episode: 552 Total Revenue: 52250  Cumulative average 51930.3 best score: 57500 epsilon 0.10 steps 106536\n",
      "Episode: 553 Total Revenue: 52350  Cumulative average 51931.1 best score: 57500 epsilon 0.10 steps 106729\n",
      "Episode: 554 Total Revenue: 51150  Cumulative average 51929.7 best score: 57500 epsilon 0.10 steps 106922\n",
      "Episode: 555 Total Revenue: 49150  Cumulative average 51924.7 best score: 57500 epsilon 0.10 steps 107115\n",
      "Episode: 556 Total Revenue: 50500  Cumulative average 51922.1 best score: 57500 epsilon 0.10 steps 107308\n",
      "Episode: 557 Total Revenue: 50850  Cumulative average 51920.2 best score: 57500 epsilon 0.10 steps 107501\n",
      "Episode: 558 Total Revenue: 52850  Cumulative average 51921.9 best score: 57500 epsilon 0.10 steps 107694\n",
      "Episode: 559 Total Revenue: 51650  Cumulative average 51921.4 best score: 57500 epsilon 0.10 steps 107887\n",
      "Episode: 560 Total Revenue: 50250  Cumulative average 51918.4 best score: 57500 epsilon 0.10 steps 108080\n",
      "Episode: 561 Total Revenue: 50900  Cumulative average 51916.6 best score: 57500 epsilon 0.10 steps 108273\n",
      "Episode: 562 Total Revenue: 50450  Cumulative average 51914.0 best score: 57500 epsilon 0.10 steps 108466\n",
      "Episode: 563 Total Revenue: 50350  Cumulative average 51911.2 best score: 57500 epsilon 0.10 steps 108659\n",
      "Episode: 564 Total Revenue: 50350  Cumulative average 51908.4 best score: 57500 epsilon 0.10 steps 108852\n",
      "Episode: 565 Total Revenue: 50150  Cumulative average 51905.3 best score: 57500 epsilon 0.10 steps 109045\n",
      "Episode: 566 Total Revenue: 50050  Cumulative average 51902.0 best score: 57500 epsilon 0.10 steps 109238\n",
      "Episode: 567 Total Revenue: 54350  Cumulative average 51906.3 best score: 57500 epsilon 0.10 steps 109431\n",
      "Episode: 568 Total Revenue: 50200  Cumulative average 51903.3 best score: 57500 epsilon 0.10 steps 109624\n",
      "Episode: 569 Total Revenue: 51750  Cumulative average 51903.1 best score: 57500 epsilon 0.10 steps 109817\n",
      "Episode: 570 Total Revenue: 50400  Cumulative average 51900.4 best score: 57500 epsilon 0.10 steps 110010\n",
      "Episode: 571 Total Revenue: 52350  Cumulative average 51901.2 best score: 57500 epsilon 0.10 steps 110203\n",
      "Episode: 572 Total Revenue: 51850  Cumulative average 51901.1 best score: 57500 epsilon 0.10 steps 110396\n",
      "Episode: 573 Total Revenue: 49850  Cumulative average 51897.6 best score: 57500 epsilon 0.10 steps 110589\n",
      "Episode: 574 Total Revenue: 53500  Cumulative average 51900.3 best score: 57500 epsilon 0.10 steps 110782\n",
      "Episode: 575 Total Revenue: 49300  Cumulative average 51895.8 best score: 57500 epsilon 0.10 steps 110975\n",
      "Episode: 576 Total Revenue: 51050  Cumulative average 51894.4 best score: 57500 epsilon 0.10 steps 111168\n",
      "Episode: 577 Total Revenue: 51500  Cumulative average 51893.7 best score: 57500 epsilon 0.10 steps 111361\n",
      "Episode: 578 Total Revenue: 51950  Cumulative average 51893.8 best score: 57500 epsilon 0.10 steps 111554\n",
      "Episode: 579 Total Revenue: 52850  Cumulative average 51895.4 best score: 57500 epsilon 0.10 steps 111747\n",
      "Episode: 580 Total Revenue: 51500  Cumulative average 51894.7 best score: 57500 epsilon 0.10 steps 111940\n",
      "Episode: 581 Total Revenue: 54850  Cumulative average 51899.8 best score: 57500 epsilon 0.10 steps 112133\n",
      "Episode: 582 Total Revenue: 53400  Cumulative average 51902.4 best score: 57500 epsilon 0.10 steps 112326\n",
      "Episode: 583 Total Revenue: 52750  Cumulative average 51903.9 best score: 57500 epsilon 0.10 steps 112519\n",
      "Episode: 584 Total Revenue: 50100  Cumulative average 51900.8 best score: 57500 epsilon 0.10 steps 112712\n",
      "Episode: 585 Total Revenue: 52600  Cumulative average 51902.0 best score: 57500 epsilon 0.10 steps 112905\n",
      "Episode: 586 Total Revenue: 52650  Cumulative average 51903.2 best score: 57500 epsilon 0.10 steps 113098\n",
      "Episode: 587 Total Revenue: 50250  Cumulative average 51900.4 best score: 57500 epsilon 0.10 steps 113291\n",
      "Episode: 588 Total Revenue: 50550  Cumulative average 51898.1 best score: 57500 epsilon 0.10 steps 113484\n",
      "Episode: 589 Total Revenue: 51250  Cumulative average 51897.0 best score: 57500 epsilon 0.10 steps 113677\n",
      "Episode: 590 Total Revenue: 48550  Cumulative average 51891.4 best score: 57500 epsilon 0.10 steps 113870\n",
      "Episode: 591 Total Revenue: 53650  Cumulative average 51894.3 best score: 57500 epsilon 0.10 steps 114063\n",
      "Episode: 592 Total Revenue: 52700  Cumulative average 51895.7 best score: 57500 epsilon 0.10 steps 114256\n",
      "Episode: 593 Total Revenue: 52850  Cumulative average 51897.3 best score: 57500 epsilon 0.10 steps 114449\n",
      "Episode: 594 Total Revenue: 54600  Cumulative average 51901.9 best score: 57500 epsilon 0.10 steps 114642\n",
      "Episode: 595 Total Revenue: 49450  Cumulative average 51897.7 best score: 57500 epsilon 0.10 steps 114835\n",
      "Episode: 596 Total Revenue: 50100  Cumulative average 51894.7 best score: 57500 epsilon 0.10 steps 115028\n",
      "Episode: 597 Total Revenue: 51400  Cumulative average 51893.9 best score: 57500 epsilon 0.10 steps 115221\n",
      "Episode: 598 Total Revenue: 54800  Cumulative average 51898.7 best score: 57500 epsilon 0.10 steps 115414\n",
      "Episode: 599 Total Revenue: 51650  Cumulative average 51898.3 best score: 57500 epsilon 0.10 steps 115607\n",
      "Episode: 600 Total Revenue: 52200  Cumulative average 51898.8 best score: 57500 epsilon 0.10 steps 115800\n",
      "Episode: 601 Total Revenue: 53100  Cumulative average 51900.8 best score: 57500 epsilon 0.10 steps 115993\n",
      "Episode: 602 Total Revenue: 50200  Cumulative average 51898.0 best score: 57500 epsilon 0.10 steps 116186\n",
      "Episode: 603 Total Revenue: 51000  Cumulative average 51896.5 best score: 57500 epsilon 0.10 steps 116379\n",
      "Episode: 604 Total Revenue: 51800  Cumulative average 51896.4 best score: 57500 epsilon 0.10 steps 116572\n",
      "Episode: 605 Total Revenue: 51050  Cumulative average 51895.0 best score: 57500 epsilon 0.10 steps 116765\n",
      "Episode: 606 Total Revenue: 50050  Cumulative average 51891.9 best score: 57500 epsilon 0.10 steps 116958\n",
      "Episode: 607 Total Revenue: 53200  Cumulative average 51894.1 best score: 57500 epsilon 0.10 steps 117151\n",
      "Episode: 608 Total Revenue: 50000  Cumulative average 51891.0 best score: 57500 epsilon 0.10 steps 117344\n",
      "Episode: 609 Total Revenue: 51200  Cumulative average 51889.8 best score: 57500 epsilon 0.10 steps 117537\n",
      "Episode: 610 Total Revenue: 51700  Cumulative average 51889.5 best score: 57500 epsilon 0.10 steps 117730\n",
      "Episode: 611 Total Revenue: 49550  Cumulative average 51885.7 best score: 57500 epsilon 0.10 steps 117923\n",
      "Episode: 612 Total Revenue: 51850  Cumulative average 51885.6 best score: 57500 epsilon 0.10 steps 118116\n",
      "Episode: 613 Total Revenue: 53750  Cumulative average 51888.7 best score: 57500 epsilon 0.10 steps 118309\n",
      "Episode: 614 Total Revenue: 52200  Cumulative average 51889.2 best score: 57500 epsilon 0.10 steps 118502\n",
      "Episode: 615 Total Revenue: 50100  Cumulative average 51886.3 best score: 57500 epsilon 0.10 steps 118695\n",
      "Episode: 616 Total Revenue: 52550  Cumulative average 51887.3 best score: 57500 epsilon 0.10 steps 118888\n",
      "Episode: 617 Total Revenue: 51200  Cumulative average 51886.2 best score: 57500 epsilon 0.10 steps 119081\n",
      "Episode: 618 Total Revenue: 51100  Cumulative average 51885.0 best score: 57500 epsilon 0.10 steps 119274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- step  166  ---------\n",
      "Action: 7, state: tensor([[ 80., 166.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8924258734319387, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 79. 165.]] reward:  450 departure:  False\n",
      "------- step  165  ---------\n",
      "Action: 7, state: tensor([[ 79., 165.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.458545318442818, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 78. 164.]] reward:  500 departure:  False\n",
      "------- step  164  ---------\n",
      "Action: 7, state: tensor([[ 78., 164.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.9565879120660978, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 77. 163.]] reward:  450 departure:  False\n",
      "------- step  163  ---------\n",
      "Action: 5, state: tensor([[ 77., 163.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.018253851760017703, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 77. 162.]] reward:  0 departure:  False\n",
      "------- step  162  ---------\n",
      "Action: 5, state: tensor([[ 77., 162.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.7537772311996749, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 76. 161.]] reward:  450 departure:  False\n",
      "------- step  161  ---------\n",
      "Action: 3, state: tensor([[ 76., 161.]], device='cuda:0')\n",
      "seat_open:  K\n",
      "random_number: 0.3907527103536934, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 76. 160.]] reward:  0 departure:  False\n",
      "------- step  160  ---------\n",
      "Action: 5, state: tensor([[ 76., 160.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.8799181658894549, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 75. 159.]] reward:  450 departure:  False\n",
      "------- step  159  ---------\n",
      "Action: 5, state: tensor([[ 75., 159.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.46116550340061424, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 75. 158.]] reward:  0 departure:  False\n",
      "------- step  158  ---------\n",
      "Action: 5, state: tensor([[ 75., 158.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.11161417979147104, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 75. 157.]] reward:  0 departure:  False\n",
      "------- step  157  ---------\n",
      "Action: 4, state: tensor([[ 75., 157.]], device='cuda:0')\n",
      "seat_open:  YM\n",
      "random_number: 0.5609972809934954, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 74. 156.]] reward:  500 departure:  False\n",
      "------- step  156  ---------\n",
      "Action: 5, state: tensor([[ 74., 156.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.11892398267251802, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 74. 155.]] reward:  0 departure:  False\n",
      "------- step  155  ---------\n",
      "Action: 5, state: tensor([[ 74., 155.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.146620765221545, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 74. 154.]] reward:  0 departure:  False\n",
      "------- step  154  ---------\n",
      "Action: 5, state: tensor([[ 74., 154.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.6950993896375197, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 73. 153.]] reward:  450 departure:  False\n",
      "------- step  153  ---------\n",
      "Action: 5, state: tensor([[ 73., 153.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.025683763824517758, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 73. 152.]] reward:  0 departure:  False\n",
      "------- step  152  ---------\n",
      "Action: 5, state: tensor([[ 73., 152.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.04477140662800838, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 73. 151.]] reward:  0 departure:  False\n",
      "------- step  151  ---------\n",
      "Action: 5, state: tensor([[ 73., 151.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.7392870097009416, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 72. 150.]] reward:  450 departure:  False\n",
      "------- step  150  ---------\n",
      "Action: 7, state: tensor([[ 72., 150.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7657765940440215, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 71. 149.]] reward:  450 departure:  False\n",
      "------- step  149  ---------\n",
      "Action: 7, state: tensor([[ 71., 149.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.6853637438688767, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 70. 148.]] reward:  450 departure:  False\n",
      "------- step  148  ---------\n",
      "Action: 7, state: tensor([[ 70., 148.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.4646576847633158, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 69. 147.]] reward:  500 departure:  False\n",
      "------- step  147  ---------\n",
      "Action: 7, state: tensor([[ 69., 147.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.775088644885087, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 68. 146.]] reward:  450 departure:  False\n",
      "------- step  146  ---------\n",
      "Action: 7, state: tensor([[ 68., 146.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7666892090360597, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 67. 145.]] reward:  450 departure:  False\n",
      "------- step  145  ---------\n",
      "Action: 7, state: tensor([[ 67., 145.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8529952143634458, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 66. 144.]] reward:  450 departure:  False\n",
      "------- step  144  ---------\n",
      "Action: 7, state: tensor([[ 66., 144.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.09399148069669527, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 66. 143.]] reward:  0 departure:  False\n",
      "------- step  143  ---------\n",
      "Action: 7, state: tensor([[ 66., 143.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.09658777790878637, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 66. 142.]] reward:  0 departure:  False\n",
      "------- step  142  ---------\n",
      "Action: 6, state: tensor([[ 66., 142.]], device='cuda:0')\n",
      "seat_open:  MK\n",
      "random_number: 0.13162984217359786, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 66. 141.]] reward:  0 departure:  False\n",
      "------- step  141  ---------\n",
      "Action: 6, state: tensor([[ 66., 141.]], device='cuda:0')\n",
      "seat_open:  MK\n",
      "random_number: 0.6380174425664437, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 65. 140.]] reward:  450 departure:  False\n",
      "------- step  140  ---------\n",
      "Action: 0, state: tensor([[ 65., 140.]], device='cuda:0')\n",
      "seat_open:  f\n",
      "random_number: 0.5784009624858738, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 65. 139.]] reward:  0 departure:  False\n",
      "------- step  139  ---------\n",
      "Action: 6, state: tensor([[ 65., 139.]], device='cuda:0')\n",
      "seat_open:  MK\n",
      "random_number: 0.3901909868934501, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 64. 138.]] reward:  500 departure:  False\n",
      "------- step  138  ---------\n",
      "Action: 5, state: tensor([[ 64., 138.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.10319554451312274, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 64. 137.]] reward:  0 departure:  False\n",
      "------- step  137  ---------\n",
      "Action: 6, state: tensor([[ 64., 137.]], device='cuda:0')\n",
      "seat_open:  MK\n",
      "random_number: 0.2929473569190879, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 63. 136.]] reward:  500 departure:  False\n",
      "------- step  136  ---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 5, state: tensor([[ 63., 136.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9728146535469221, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 62. 135.]] reward:  450 departure:  False\n",
      "------- step  135  ---------\n",
      "Action: 5, state: tensor([[ 62., 135.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9555004875020502, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 61. 134.]] reward:  450 departure:  False\n",
      "------- step  134  ---------\n",
      "Action: 5, state: tensor([[ 61., 134.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.29345095086057715, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 60. 133.]] reward:  800 departure:  False\n",
      "------- step  133  ---------\n",
      "Action: 5, state: tensor([[ 60., 133.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.11925827124049082, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 60. 132.]] reward:  0 departure:  False\n",
      "------- step  132  ---------\n",
      "Action: 5, state: tensor([[ 60., 132.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.8123378467653193, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 59. 131.]] reward:  450 departure:  False\n",
      "------- step  131  ---------\n",
      "Action: 5, state: tensor([[ 59., 131.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.13449348639979664, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 59. 130.]] reward:  0 departure:  False\n",
      "------- step  130  ---------\n",
      "Action: 5, state: tensor([[ 59., 130.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3771942048900414, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 58. 129.]] reward:  800 departure:  False\n",
      "------- step  129  ---------\n",
      "Action: 5, state: tensor([[ 58., 129.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3000167447371418, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 57. 128.]] reward:  800 departure:  False\n",
      "------- step  128  ---------\n",
      "Action: 5, state: tensor([[ 57., 128.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.31011222961670937, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 56. 127.]] reward:  800 departure:  False\n",
      "------- step  127  ---------\n",
      "Action: 7, state: tensor([[ 56., 127.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.09265492781550067, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 56. 126.]] reward:  0 departure:  False\n",
      "------- step  126  ---------\n",
      "Action: 2, state: tensor([[ 56., 126.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.056135437328953874, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 56. 125.]] reward:  0 departure:  False\n",
      "------- step  125  ---------\n",
      "Action: 7, state: tensor([[ 56., 125.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.2285502894823549, customer_index: 1, customer_type: Bus1\n",
      "customer type:  Bus1\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 55. 124.]] reward:  800 departure:  False\n",
      "------- step  124  ---------\n",
      "Action: 7, state: tensor([[ 55., 124.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.028735338916476505, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 55. 123.]] reward:  0 departure:  False\n",
      "------- step  123  ---------\n",
      "Action: 2, state: tensor([[ 55., 123.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.3494491980726957, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 54. 122.]] reward:  500 departure:  False\n",
      "------- step  122  ---------\n",
      "Action: 6, state: tensor([[ 54., 122.]], device='cuda:0')\n",
      "seat_open:  MK\n",
      "random_number: 0.9269955502261173, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 53. 121.]] reward:  450 departure:  False\n",
      "------- step  121  ---------\n",
      "Action: 7, state: tensor([[ 53., 121.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.3290917411600758, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y', 'M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 52. 120.]] reward:  500 departure:  False\n",
      "------- step  120  ---------\n",
      "Action: 3, state: tensor([[ 52., 120.]], device='cuda:0')\n",
      "seat_open:  K\n",
      "random_number: 0.5879761556709061, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 52. 119.]] reward:  0 departure:  False\n",
      "------- step  119  ---------\n",
      "Action: 5, state: tensor([[ 52., 119.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9790202305917763, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 51. 118.]] reward:  450 departure:  False\n",
      "------- step  118  ---------\n",
      "Action: 5, state: tensor([[ 51., 118.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9689984532456748, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 50. 117.]] reward:  450 departure:  False\n",
      "------- step  117  ---------\n",
      "Action: 5, state: tensor([[ 50., 117.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.5572574707246369, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 50. 116.]] reward:  0 departure:  False\n",
      "------- step  116  ---------\n",
      "Action: 5, state: tensor([[ 50., 116.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.13657694529968578, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 50. 115.]] reward:  0 departure:  False\n",
      "------- step  115  ---------\n",
      "Action: 5, state: tensor([[ 50., 115.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9707190574468184, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 49. 114.]] reward:  450 departure:  False\n",
      "------- step  114  ---------\n",
      "Action: 5, state: tensor([[ 49., 114.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.13807990461928032, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 49. 113.]] reward:  0 departure:  False\n",
      "------- step  113  ---------\n",
      "Action: 1, state: tensor([[ 49., 113.]], device='cuda:0')\n",
      "seat_open:  Y\n",
      "random_number: 0.16166491760574708, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 49. 112.]] reward:  0 departure:  False\n",
      "------- step  112  ---------\n",
      "Action: 0, state: tensor([[ 49., 112.]], device='cuda:0')\n",
      "seat_open:  f\n",
      "random_number: 0.5173973685347595, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 49. 111.]] reward:  0 departure:  False\n",
      "------- step  111  ---------\n",
      "Action: 5, state: tensor([[ 49., 111.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3228210619644535, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 48. 110.]] reward:  800 departure:  False\n",
      "------- step  110  ---------\n",
      "Action: 0, state: tensor([[ 48., 110.]], device='cuda:0')\n",
      "seat_open:  f\n",
      "random_number: 0.4771091411955264, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 48. 109.]] reward:  0 departure:  False\n",
      "------- step  109  ---------\n",
      "Action: 7, state: tensor([[ 48., 109.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7773527317086317, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 47. 108.]] reward:  450 departure:  False\n",
      "------- step  108  ---------\n",
      "Action: 7, state: tensor([[ 47., 108.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.1692403319858684, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 47. 107.]] reward:  0 departure:  False\n",
      "------- step  107  ---------\n",
      "Action: 0, state: tensor([[ 47., 107.]], device='cuda:0')\n",
      "seat_open:  f\n",
      "random_number: 0.36718396990992974, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 47. 106.]] reward:  0 departure:  False\n",
      "------- step  106  ---------\n",
      "Action: 7, state: tensor([[ 47., 106.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.1681575659881338, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 47. 105.]] reward:  0 departure:  False\n",
      "------- step  105  ---------\n",
      "Action: 7, state: tensor([[ 47., 105.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7988895550887272, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 46. 104.]] reward:  450 departure:  False\n",
      "------- step  104  ---------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: 1, state: tensor([[ 46., 104.]], device='cuda:0')\n",
      "seat_open:  Y\n",
      "random_number: 0.02311269187715914, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 46. 103.]] reward:  0 departure:  False\n",
      "------- step  103  ---------\n",
      "Action: 7, state: tensor([[ 46., 103.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.3471947655130896, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y', 'M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 45. 102.]] reward:  500 departure:  False\n",
      "------- step  102  ---------\n",
      "Action: 7, state: tensor([[ 45., 102.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7801096072574085, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 44. 101.]] reward:  450 departure:  False\n",
      "------- step  101  ---------\n",
      "Action: 4, state: tensor([[ 44., 101.]], device='cuda:0')\n",
      "seat_open:  YM\n",
      "random_number: 0.5315744420170865, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[ 43. 100.]] reward:  500 departure:  False\n",
      "------- step  100  ---------\n",
      "Action: 7, state: tensor([[ 43., 100.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.15862386771172055, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[43. 99.]] reward:  0 departure:  False\n",
      "------- step  99  ---------\n",
      "Action: 5, state: tensor([[43., 99.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.36034986961531523, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[42. 98.]] reward:  800 departure:  False\n",
      "------- step  98  ---------\n",
      "Action: 5, state: tensor([[42., 98.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.345389210981222, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[41. 97.]] reward:  800 departure:  False\n",
      "------- step  97  ---------\n",
      "Action: 5, state: tensor([[41., 97.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.487212751517655, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[41. 96.]] reward:  0 departure:  False\n",
      "------- step  96  ---------\n",
      "Action: 5, state: tensor([[41., 96.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.7618860150462996, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[40. 95.]] reward:  450 departure:  False\n",
      "------- step  95  ---------\n",
      "Action: 5, state: tensor([[40., 95.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9779995560523085, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[39. 94.]] reward:  450 departure:  False\n",
      "------- step  94  ---------\n",
      "Action: 5, state: tensor([[39., 94.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.09678218199331046, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[39. 93.]] reward:  0 departure:  False\n",
      "------- step  93  ---------\n",
      "Action: 5, state: tensor([[39., 93.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.39350377718310847, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[38. 92.]] reward:  800 departure:  False\n",
      "------- step  92  ---------\n",
      "Action: 7, state: tensor([[38., 92.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8505020322174338, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[37. 91.]] reward:  450 departure:  False\n",
      "------- step  91  ---------\n",
      "Action: 5, state: tensor([[37., 91.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3163159782265843, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[36. 90.]] reward:  800 departure:  False\n",
      "------- step  90  ---------\n",
      "Action: 5, state: tensor([[36., 90.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.11472870386459633, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[36. 89.]] reward:  0 departure:  False\n",
      "------- step  89  ---------\n",
      "Action: 2, state: tensor([[36., 89.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.29918401614868817, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[35. 88.]] reward:  500 departure:  False\n",
      "------- step  88  ---------\n",
      "Action: 5, state: tensor([[35., 88.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.5016989640741417, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[35. 87.]] reward:  0 departure:  False\n",
      "------- step  87  ---------\n",
      "Action: 5, state: tensor([[35., 87.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.11920008662172676, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[35. 86.]] reward:  0 departure:  False\n",
      "------- step  86  ---------\n",
      "Action: 5, state: tensor([[35., 86.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3049016974077081, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[34. 85.]] reward:  800 departure:  False\n",
      "------- step  85  ---------\n",
      "Action: 5, state: tensor([[34., 85.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.3920040364895635, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[33. 84.]] reward:  800 departure:  False\n",
      "------- step  84  ---------\n",
      "Action: 5, state: tensor([[33., 84.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.4467014451781586, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[33. 83.]] reward:  0 departure:  False\n",
      "------- step  83  ---------\n",
      "Action: 5, state: tensor([[33., 83.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.723057969838861, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[32. 82.]] reward:  450 departure:  False\n",
      "------- step  82  ---------\n",
      "Action: 5, state: tensor([[32., 82.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.6185218282009228, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[31. 81.]] reward:  450 departure:  False\n",
      "------- step  81  ---------\n",
      "Action: 5, state: tensor([[31., 81.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.06396036300984687, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[31. 80.]] reward:  0 departure:  False\n",
      "------- step  80  ---------\n",
      "Action: 5, state: tensor([[31., 80.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.6165407957878887, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[30. 79.]] reward:  450 departure:  False\n",
      "------- step  79  ---------\n",
      "Action: 2, state: tensor([[30., 79.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.8418604217609038, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[30. 78.]] reward:  0 departure:  False\n",
      "------- step  78  ---------\n",
      "Action: 7, state: tensor([[30., 78.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8691820852471244, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[29. 77.]] reward:  450 departure:  False\n",
      "------- step  77  ---------\n",
      "Action: 5, state: tensor([[29., 77.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.8829644000919238, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[28. 76.]] reward:  450 departure:  False\n",
      "------- step  76  ---------\n",
      "Action: 3, state: tensor([[28., 76.]], device='cuda:0')\n",
      "seat_open:  K\n",
      "random_number: 0.6398310590667213, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[27. 75.]] reward:  450 departure:  False\n",
      "------- step  75  ---------\n",
      "Action: 5, state: tensor([[27., 75.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9861064400922217, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[26. 74.]] reward:  450 departure:  False\n",
      "------- step  74  ---------\n",
      "Action: 5, state: tensor([[26., 74.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.566024726698028, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[26. 73.]] reward:  0 departure:  False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- step  73  ---------\n",
      "Action: 5, state: tensor([[26., 73.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.285563483546995, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[25. 72.]] reward:  800 departure:  False\n",
      "------- step  72  ---------\n",
      "Action: 5, state: tensor([[25., 72.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.9984531746442914, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[24. 71.]] reward:  450 departure:  False\n",
      "------- step  71  ---------\n",
      "Action: 5, state: tensor([[24., 71.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.6016497298711968, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[23. 70.]] reward:  450 departure:  False\n",
      "------- step  70  ---------\n",
      "Action: 5, state: tensor([[23., 70.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.7819037899938438, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[22. 69.]] reward:  450 departure:  False\n",
      "------- step  69  ---------\n",
      "Action: 5, state: tensor([[22., 69.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.33916499409384415, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[21. 68.]] reward:  800 departure:  False\n",
      "------- step  68  ---------\n",
      "Action: 5, state: tensor([[21., 68.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.6444757755231604, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[20. 67.]] reward:  450 departure:  False\n",
      "------- step  67  ---------\n",
      "Action: 7, state: tensor([[20., 67.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.3884132619177527, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['Y', 'M']\n",
      "chosen seat:  M\n",
      "observation:  [[19. 66.]] reward:  500 departure:  False\n",
      "------- step  66  ---------\n",
      "Action: 2, state: tensor([[19., 66.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.3301380060318845, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[18. 65.]] reward:  500 departure:  False\n",
      "------- step  65  ---------\n",
      "Action: 7, state: tensor([[18., 65.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8379822440819885, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[17. 64.]] reward:  450 departure:  False\n",
      "------- step  64  ---------\n",
      "Action: 7, state: tensor([[17., 64.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.0005154295928336827, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[17. 63.]] reward:  0 departure:  False\n",
      "------- step  63  ---------\n",
      "Action: 7, state: tensor([[17., 63.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.5320083980932395, customer_index: 3, customer_type: Leis1\n",
      "customer type:  Leis1\n",
      "preference seats:  ['M']\n",
      "chosen seat:  M\n",
      "observation:  [[16. 62.]] reward:  500 departure:  False\n",
      "------- step  62  ---------\n",
      "Action: 7, state: tensor([[16., 62.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.761565492892757, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[15. 61.]] reward:  450 departure:  False\n",
      "------- step  61  ---------\n",
      "Action: 7, state: tensor([[15., 61.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.6966183008701087, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[14. 60.]] reward:  450 departure:  False\n",
      "------- step  60  ---------\n",
      "Action: 7, state: tensor([[14., 60.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7186419837854177, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[13. 59.]] reward:  450 departure:  False\n",
      "------- step  59  ---------\n",
      "Action: 7, state: tensor([[13., 59.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.99268738759755, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[12. 58.]] reward:  450 departure:  False\n",
      "------- step  58  ---------\n",
      "Action: 2, state: tensor([[12., 58.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.7690850175584243, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[12. 57.]] reward:  0 departure:  False\n",
      "------- step  57  ---------\n",
      "Action: 2, state: tensor([[12., 57.]], device='cuda:0')\n",
      "seat_open:  M\n",
      "random_number: 0.16830035787499087, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[12. 56.]] reward:  0 departure:  False\n",
      "------- step  56  ---------\n",
      "Action: 5, state: tensor([[12., 56.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.8543506608800161, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[11. 55.]] reward:  450 departure:  False\n",
      "------- step  55  ---------\n",
      "Action: 5, state: tensor([[11., 55.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.02948106957836616, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[11. 54.]] reward:  0 departure:  False\n",
      "------- step  54  ---------\n",
      "Action: 5, state: tensor([[11., 54.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.03062145609313438, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[11. 53.]] reward:  0 departure:  False\n",
      "------- step  53  ---------\n",
      "Action: 5, state: tensor([[11., 53.]], device='cuda:0')\n",
      "seat_open:  YK\n",
      "random_number: 0.65921990411019, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[10. 52.]] reward:  450 departure:  False\n",
      "------- step  52  ---------\n",
      "Action: 7, state: tensor([[10., 52.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.27120823511923664, customer_index: 1, customer_type: Bus1\n",
      "customer type:  Bus1\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 9. 51.]] reward:  800 departure:  False\n",
      "------- step  51  ---------\n",
      "Action: 7, state: tensor([[ 9., 51.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7754634600142024, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 8. 50.]] reward:  450 departure:  False\n",
      "------- step  50  ---------\n",
      "Action: 1, state: tensor([[ 8., 50.]], device='cuda:0')\n",
      "seat_open:  Y\n",
      "random_number: 0.6293620789263906, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 8. 49.]] reward:  0 departure:  False\n",
      "------- step  49  ---------\n",
      "Action: 7, state: tensor([[ 8., 49.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.7422913466283063, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 7. 48.]] reward:  450 departure:  False\n",
      "------- step  48  ---------\n",
      "Action: 7, state: tensor([[ 7., 48.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.2194660643077594, customer_index: 1, customer_type: Bus1\n",
      "customer type:  Bus1\n",
      "preference seats:  ['Y']\n",
      "chosen seat:  Y\n",
      "observation:  [[ 6. 47.]] reward:  800 departure:  False\n",
      "------- step  47  ---------\n",
      "Action: 7, state: tensor([[ 6., 47.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.07874194338351026, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 6. 46.]] reward:  0 departure:  False\n",
      "------- step  46  ---------\n",
      "Action: 7, state: tensor([[ 6., 46.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.9164841787710573, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 5. 45.]] reward:  450 departure:  False\n",
      "------- step  45  ---------\n",
      "Action: 7, state: tensor([[ 5., 45.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.1483119873757418, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 5. 44.]] reward:  0 departure:  False\n",
      "------- step  44  ---------\n",
      "Action: 7, state: tensor([[ 5., 44.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8712161577739699, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 4. 43.]] reward:  450 departure:  False\n",
      "------- step  43  ---------\n",
      "Action: 1, state: tensor([[ 4., 43.]], device='cuda:0')\n",
      "seat_open:  Y\n",
      "random_number: 0.9240232483537636, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 4. 42.]] reward:  0 departure:  False\n",
      "------- step  42  ---------\n",
      "Action: 7, state: tensor([[ 4., 42.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.6264100223103511, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 3. 41.]] reward:  450 departure:  False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- step  41  ---------\n",
      "Action: 7, state: tensor([[ 3., 41.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.701029027435423, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 2. 40.]] reward:  450 departure:  False\n",
      "------- step  40  ---------\n",
      "Action: 7, state: tensor([[ 2., 40.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.8502382782801639, customer_index: 5, customer_type: Leis3\n",
      "customer type:  Leis3\n",
      "preference seats:  ['K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 1. 39.]] reward:  450 departure:  False\n",
      "------- step  39  ---------\n",
      "Action: 7, state: tensor([[ 1., 39.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.06699662507731363, customer_index: 0, customer_type: f\n",
      "customer type:  f\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 1. 38.]] reward:  0 departure:  False\n",
      "------- step  38  ---------\n",
      "Action: 0, state: tensor([[ 1., 38.]], device='cuda:0')\n",
      "seat_open:  f\n",
      "random_number: 0.3850852650292662, customer_index: 2, customer_type: Bus2\n",
      "customer type:  Bus2\n",
      "preference seats:  []\n",
      "chosen seat:  f\n",
      "observation:  [[ 1. 37.]] reward:  0 departure:  False\n",
      "------- step  37  ---------\n",
      "Action: 7, state: tensor([[ 1., 37.]], device='cuda:0')\n",
      "seat_open:  YMK\n",
      "random_number: 0.6327286301537217, customer_index: 4, customer_type: Leis2\n",
      "customer type:  Leis2\n",
      "preference seats:  ['M', 'K']\n",
      "chosen seat:  K\n",
      "observation:  [[ 0. 36.]] reward:  450 departure:  False\n",
      "------- step  36  ---------\n",
      "Action: 6, state: tensor([[ 0., 36.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 35.]] reward:  0 departure:  False\n",
      "------- step  35  ---------\n",
      "Action: 6, state: tensor([[ 0., 35.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 34.]] reward:  0 departure:  False\n",
      "------- step  34  ---------\n",
      "Action: 6, state: tensor([[ 0., 34.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 33.]] reward:  0 departure:  False\n",
      "------- step  33  ---------\n",
      "Action: 6, state: tensor([[ 0., 33.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 32.]] reward:  0 departure:  False\n",
      "------- step  32  ---------\n",
      "Action: 6, state: tensor([[ 0., 32.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 31.]] reward:  0 departure:  False\n",
      "------- step  31  ---------\n",
      "Action: 7, state: tensor([[ 0., 31.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 30.]] reward:  0 departure:  False\n",
      "------- step  30  ---------\n",
      "Action: 7, state: tensor([[ 0., 30.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 29.]] reward:  0 departure:  False\n",
      "------- step  29  ---------\n",
      "Action: 4, state: tensor([[ 0., 29.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 28.]] reward:  0 departure:  False\n",
      "------- step  28  ---------\n",
      "Action: 4, state: tensor([[ 0., 28.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 27.]] reward:  0 departure:  False\n",
      "------- step  27  ---------\n",
      "Action: 4, state: tensor([[ 0., 27.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 26.]] reward:  0 departure:  False\n",
      "------- step  26  ---------\n",
      "Action: 4, state: tensor([[ 0., 26.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 25.]] reward:  0 departure:  False\n",
      "------- step  25  ---------\n",
      "Action: 4, state: tensor([[ 0., 25.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 24.]] reward:  0 departure:  False\n",
      "------- step  24  ---------\n",
      "Action: 4, state: tensor([[ 0., 24.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 23.]] reward:  0 departure:  False\n",
      "------- step  23  ---------\n",
      "Action: 6, state: tensor([[ 0., 23.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 22.]] reward:  0 departure:  False\n",
      "------- step  22  ---------\n",
      "Action: 4, state: tensor([[ 0., 22.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 21.]] reward:  0 departure:  False\n",
      "------- step  21  ---------\n",
      "Action: 4, state: tensor([[ 0., 21.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 20.]] reward:  0 departure:  False\n",
      "------- step  20  ---------\n",
      "Action: 4, state: tensor([[ 0., 20.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 19.]] reward:  0 departure:  False\n",
      "------- step  19  ---------\n",
      "Action: 4, state: tensor([[ 0., 19.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 18.]] reward:  0 departure:  False\n",
      "------- step  18  ---------\n",
      "Action: 4, state: tensor([[ 0., 18.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 17.]] reward:  0 departure:  False\n",
      "------- step  17  ---------\n",
      "Action: 4, state: tensor([[ 0., 17.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 16.]] reward:  0 departure:  False\n",
      "------- step  16  ---------\n",
      "Action: 4, state: tensor([[ 0., 16.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 15.]] reward:  0 departure:  False\n",
      "------- step  15  ---------\n",
      "Action: 3, state: tensor([[ 0., 15.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 14.]] reward:  0 departure:  False\n",
      "------- step  14  ---------\n",
      "Action: 3, state: tensor([[ 0., 14.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 13.]] reward:  0 departure:  False\n",
      "------- step  13  ---------\n",
      "Action: 3, state: tensor([[ 0., 13.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 12.]] reward:  0 departure:  False\n",
      "------- step  12  ---------\n",
      "Action: 3, state: tensor([[ 0., 12.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 11.]] reward:  0 departure:  False\n",
      "------- step  11  ---------\n",
      "Action: 0, state: tensor([[ 0., 11.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[ 0. 10.]] reward:  0 departure:  False\n",
      "------- step  10  ---------\n",
      "Action: 1, state: tensor([[ 0., 10.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 9.]] reward:  0 departure:  False\n",
      "------- step  9  ---------\n",
      "Action: 6, state: tensor([[0., 9.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 8.]] reward:  0 departure:  False\n",
      "------- step  8  ---------\n",
      "Action: 0, state: tensor([[0., 8.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 7.]] reward:  0 departure:  False\n",
      "------- step  7  ---------\n",
      "Action: 3, state: tensor([[0., 7.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 6.]] reward:  0 departure:  False\n",
      "------- step  6  ---------\n",
      "Action: 3, state: tensor([[0., 6.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 5.]] reward:  0 departure:  False\n",
      "------- step  5  ---------\n",
      "Action: 1, state: tensor([[0., 5.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 4.]] reward:  0 departure:  False\n",
      "------- step  4  ---------\n",
      "Action: 7, state: tensor([[0., 4.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 3.]] reward:  0 departure:  False\n",
      "------- step  3  ---------\n",
      "Action: 4, state: tensor([[0., 3.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 2.]] reward:  0 departure:  False\n",
      "------- step  2  ---------\n",
      "Action: 4, state: tensor([[0., 2.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 1.]] reward:  0 departure:  False\n",
      "------- step  1  ---------\n",
      "Action: 7, state: tensor([[0., 1.]], device='cuda:0')\n",
      "No remaining seat.\n",
      "observation:  [[0. 0.]] reward:  0 departure:  True\n",
      "Episode: 9, Total Revenue: tensor([52750], device='cuda:0'), Cumulative average: [52630.]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Training parameters\n",
    "num_episodes = 3000\n",
    "DQN_total_revenues = []\n",
    "DQN_cumulative_average = []\n",
    "DQN_per_50_avg = []\n",
    "\n",
    "env = AirlineEnvironment(\"Single route parallel flight.v0\")\n",
    "agent = DQNAgent(gamma=0.99, epsilon=1, lr=0.001,\n",
    "                 input_dims=len(env.state),\n",
    "                 n_actions=env.action_space.n, mem_size=100000, eps_min=0.1,\n",
    "                 batch_size=512, replace=1000, eps_dec=1e-5)\n",
    "\n",
    "n_step = 0\n",
    "best_score = 0\n",
    "\n",
    "# Start Training\n",
    "for episode in range(1, num_episodes+1):\n",
    "    \n",
    "    # Initialize environment\n",
    "    # print(\"---------- Episode \", episode, \"-----------\")\n",
    "    observation = env.reset()\n",
    "    total_revenue = 0 # Initialize total revenue\n",
    "    departure = None\n",
    "    \n",
    "    while not departure:\n",
    "        \n",
    "        # print(\"------- step \" , env.max_period - n_step,\" ---------\")\n",
    "        \n",
    "        # agent select action\n",
    "        action = agent.choose_action(observation)\n",
    "        # print(\"action\", action)\n",
    "\n",
    "        # env return observation\n",
    "        observation_, reward, departure = env.step(observation, action)\n",
    "        # print(\"observation_: \", observation, \"reward: \",  reward, \"departure: \", departure)\n",
    "        total_revenue += reward # Update total revenue\n",
    "\n",
    "        # agent memorize transition\n",
    "        agent.store_transition(observation, action, reward, observation_, departure)\n",
    "        agent.learn()\n",
    "\n",
    "        # Move on to the next state\n",
    "        observation = observation_ \n",
    "        n_step += 1\n",
    "\n",
    "    if total_revenue > best_score:\n",
    "        best_score = total_revenue\n",
    "        \n",
    "    DQN_total_revenues.append(total_revenue) \n",
    "    DQN_per_50_avg.append(np.mean(DQN_total_revenues[-50:])) \n",
    "    DQN_cumulative_avg = sum(DQN_total_revenues) / (episode)\n",
    "    DQN_cumulative_average.append(DQN_cumulative_avg)\n",
    "    # print(f\"Episode: {episode}, Total Revenue: {total_revenue}, Cumulative average: {DQN_cumulative_avg}\")\n",
    "    print('Episode:',episode ,'Total Revenue:', total_revenue,\n",
    "             ' Cumulative average %.1f' % DQN_cumulative_avg, 'best score:', best_score,\n",
    "            'epsilon %.2f' % agent.epsilon, 'steps', n_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plt.figure(figsize=(10, 6))  \n",
    "plt.plot(range(num_episodes), DQN_total_revenues, label='DQN each episode', alpha=0.5, color='b')\n",
    "plt.plot(range(num_episodes), DQN_per_50_avg, label='DQN per 50 episode', alpha=0.5, color='green')\n",
    "plt.plot(range(num_episodes), DQN_cumulative_average, label='DQN Cumulative')\n",
    "plt.axhline(y=dp, color='r', label='DP')\n",
    "plt.axhline(y=fcfs, color='orange', label='FCFS')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.title('Total Reward per Episode')\n",
    "plt.legend()  \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
